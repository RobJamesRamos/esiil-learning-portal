[
  {
    "objectID": "notebooks/04-air-quality/air-quality.html",
    "href": "notebooks/04-air-quality/air-quality.html",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "",
    "text": "The Gila River Reservation south of Phoenix, AZ is the ancestral home of the Akimel O‚Äôotham and Tohono O‚Äôodham tribes. The Gila River area was known for its agriculture, with miles of canals providing irrigation. However, in the 1800s, European colonizers upstream installed dams which cut off water supply. This resulted in the collapse of Gila River agriculture and sky-rocketing rates of diabetes and heart disease in the community as they were force to subsist only on US government surplus rations.\nIn 2004, the Gila River community won back much of its water rights in court. The settlement granted senior water rights nearly matching pre-colonial water use. Work has begun to rebuild the agriculture in the Gila River Reservation. According to the Gila River Indian Community, ‚ÄúIt will take years to complete but in the end the community members will once again hear the sweet music of rushing water.‚Äù\n&gt; Image source: New York Times"
  },
  {
    "objectID": "notebooks/04-air-quality/air-quality.html#observing-vegetation-health-from-space",
    "href": "notebooks/04-air-quality/air-quality.html#observing-vegetation-health-from-space",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "Observing vegetation health from space",
    "text": "Observing vegetation health from space\nWe will look at the recovery of agriculture in the area over the following 19 years using the summertime NDVI (Normalized Difference Vegetation Index). How does it work? First, we need to learn about spectral reflectance signatures.\nEvery object reflects some wavelengths of light more or less than others. We can see this with our eyes, since, for example, plants reflect a lot of green in the summer, and then as that green diminishes in the fall they look more yellow or orange. The image below shows spectral signatures for water, soil, and vegetation:\n &gt; Image source: SEOS Project\nHealthy vegetation reflects a lot of Near-InfraRed (NIR) radiation. Dead ve Less healthy vegetation reflects a similar amounts of the visible light spectra, but less NIR radiation. We don‚Äôt see a huge drop in Green radiation until the plant is very stressed or dead. That means that NIR allows us to get ahead of what we can see with our eyes.\n &gt; Image source: Spectral signature literature review by px39n\nDifferent species of plants reflect different spectral signatures, but the pattern of the signatures are similar. NDVI compares the amount of NIR reflectance to the amount of Red reflectance, thus accounting for many of the species differences and isolating the health of the plant. The formula for calculating NDVI is:\n\\[NDVI = \\frac{(NIR - Red)}{(NIR + Red)}\\]\nRead more about NDVI and other vegetation indices: * earthdatascience.org * USGS"
  },
  {
    "objectID": "notebooks/04-air-quality/air-quality.html#import-necessary-libraries",
    "href": "notebooks/04-air-quality/air-quality.html#import-necessary-libraries",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "Import necessary libraries",
    "text": "Import necessary libraries\nIn the cell below, making sure to keep the packages in order, add packages for: * Working with DataFrames * Generating interactive maps * Downloading files from the web\nüå∂ What are we using the rest of these packages for? See if you can figure it out as you complete the notebook.\n\nimport getpass\nimport json\nimport os\nimport pathlib\nimport re\nimport time\nfrom glob import glob\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport rioxarray as rxr\nimport xarray as xr\n\n# BEGIN SOLUTION\nimport getpass\nimport json\nimport os\nimport pathlib\nimport re\nimport time\nfrom glob import glob\n\nimport folium\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport requests\nimport rioxarray as rxr\nimport xarray as xr\n# END SOLUTION\n\nWe have one more setup task. We‚Äôre not going to be able to load all our data directly from the web to Python this time. That means we need to set up a place for it.\n\nGOTCHA ALERT: A lot of times in Python we say ‚Äúdirectory‚Äù to mean a ‚Äúfolder‚Äù on your computer. The two words mean the same thing.\n\nüíª In the cell below, replace ‚Äòdata-dir‚Äô with a descriptive directory name.\n\ndata_dir = os.path.join(pathlib.Path.home(), 'nd-ndvi')\n# Make the data directory\nos.makedirs(data_dir)"
  },
  {
    "objectID": "notebooks/04-air-quality/air-quality.html#study-area-the-gila-river-reservation",
    "href": "notebooks/04-air-quality/air-quality.html#study-area-the-gila-river-reservation",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "Study Area: The Gila River Reservation",
    "text": "Study Area: The Gila River Reservation\n\nEarth Data Science data formats\nIn Earth Data Science, we get data in three main formats:\n\n\n\n\n\n\n\n\n\nData type\nDescriptions\nCommon file formats\nPython type\n\n\n\n\nTime Series\nThe same data points (e.g.¬†streamflow) collected multiple times over time\nTabular formats (e.g.¬†.csv, or .xlsx)\npandas DataFrame\n\n\nVector\nPoints, lines, and areas (with coordinates)\nShapefile (often an archive like a .zip file because a Shapefile is actually a collection of at least 3 files)\ngeopandas GeoDataFrame\n\n\nRaster\nEvenly spaced spatial grid (with coordinates)\nGeoTIFF (.tif), NetCDF (.nc), HDF (.hdf)\nrioxarray DataArray\n\n\n\nüìñ Read more about vector data and raster data in the textbook.\n‚úé For this coding challenge, we are interested in the boundaries of American Indian Reservations to define our study area (the Gila River Reservation). In the cell below, answer the following question: What data type do you think the reservation boundaries will be?\nüíª Your task: * Search the data.gov catalog for ‚ÄúAmerican Indian Tribal Subdivision‚Äù * Get a link to the file containing Tribal subdivision boundaries as a .zip file and save it as a Python variable * Load the data into Python using the geopandas library, e.g.:\ngpd.read_file(url)\n\n# BEGIN SOLUTION\nurl = (\n    'https://www2.census.gov/geo/tiger/TIGER2020/AITSN/tl_2020_us_aitsn.zip')\n\ngdf = gpd.read_file(url)\ngdf\n# END SOLUTION\n\n\nans_gdf = _\ngdf_pts = 0\n\nif isinstance(ans_gdf, gpd.GeoDataFrame):\n    print('\\u2705 Great work! You downloaded and opened a GeoDataFrame')\n    gdf_pts +=2\nelse:\n    print('\\u274C Hmm, your answer is not a GeoDataFrame')\n\nprint('\\u27A1 You earned {} of 2 points for downloading data'.format(gdf_pts))\n\n\n\nSite Map\nThe code below will help you to draw the Tribal subdivision boundaris on an interactive map.\nüíª Your task: * Ask ChatGPT how to plot a shapefile on a folium map * Adapt the code to use the boundary data you downloaded\n\nGOTCHA ALERT: Make sure to call your map at the end of the cell so that it will display in your Notebook\n\nüå∂ Customize your plot - can you add ESRI World Imagery as the basemap/background?\n\n# BEGIN SOLUTION\nm = folium.Map(location=[37, -95.7], zoom_start=5)\n\n# Use ESRI World Imagery as the basemap\nfolium.raster_layers.TileLayer(\n    tiles=(\n        'https://server.arcgisonline.com/ArcGIS/rest/services/'\n        'World_Imagery/MapServer/tile/{z}/{y}/{x}'),\n    attr=(\n        'Tiles &copy; Esri &mdash; '\n        'Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, '\n        'Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community')\n).add_to(m)\n\nfolium.GeoJson(data=gdf.to_json()).add_to(m)\n\nm\n# END SOLUTION\n\nNotice that we used the AIANNHCE attribute in the popup on the map above. That‚Äôs because the AIANNHCE is a number that indicates which larger reservation each subdivision is a part of.\nYour task: * Research the Gila River Reservation. Can you find it on your map? * Find the AIANNHCE number for the Gila River Reservation and use it to select only subdivisions in that group. * Use the .dissolve() method of your GeoDataFrame to merge all the subdivisions into one boundary * Test your code by plotting the final boundary.\n\n# BEGIN SOLUTION\n# Get the full Gila River Reservation shape\ngila_gdf = gdf[gdf.AIANNHCE=='1310'].dissolve()\n\n# Check geometric operations\ngila_gdf.plot()\n# END SOLUTION"
  },
  {
    "objectID": "notebooks/04-air-quality/air-quality.html#exploring-the-appeears-api-for-nasa-earthdata-access",
    "href": "notebooks/04-air-quality/air-quality.html#exploring-the-appeears-api-for-nasa-earthdata-access",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "Exploring the AppEEARS API for NASA Earthdata access",
    "text": "Exploring the AppEEARS API for NASA Earthdata access\nOver the next four cells, you will download MODIS NDVI data for the study period. MODIS is a multispectral instrument that measures Red and NIR data (and so can be used for NDVI). There are two MODIS sensors on two different platforms: satellites Terra and Aqua.\nüìñ Learn more about MODIS datasets and science\nSince we‚Äôre asking for a special download that only covers our study area, we can‚Äôt just find a link to the data - we have to negotiate with the data server. We‚Äôre doing this using the APPEEARS API (Application Programming Interface). The API makes it possible for you to request data using code. The steps of your conversation with the data server will be: 1. Log in so the server knows who you are 2. Submit your data request 3. Wait until the server has processed your request and your data is ready 4. Download the files containing your request.\nüíª Often when we want to do something more complex in coding we find an example and modify it. This download code is already almost a working example. Your task will be: * Enter your NASA Earthdata username and password when prompted * Replace the start and end dates in the task parameters. You will want as many years of data as you can get! * Replace gdf with the name of your site geodataframe.\n\nGOTCHA ALERT make sure to use only the boundary of the Gila River Reservation, and not the full boundary of all subdivisions! You don‚Äôt want to download too much data you don‚Äôt need and run out of space.\n\nüå∂ What would the product and layer name be if you were trying to download Landsat Surface Temperature Analysis Ready Data (ARD) instead of MODIS NDVI?\n\n1. Log in to the Earthdata AppEEARS API\n\n# Ask for the user's username and password\nusername = input('NASA Earthdata Username: ')\npassword = getpass.getpass('NASA Earthdata Password: ')\n\n# Set up authentication and submit login request\ns = requests.Session()\ns.auth = (username, password)\nlogin_resp = s.post(\"https://appeears.earthdatacloud.nasa.gov/api/login\")\n\n# Set up the authorization header with the new token to use in later commands\nauth_header = (\n    '{token_type} {token}'\n    .format(**login_resp.json()))\n\n\n\n2. Submit the task request\n\n# Task parameters\ntask = {\n    'task_type': 'area',\n    'task_name': 'nd-ndvi',\n    'params': {\n        'dates': [\n            {\n                'startDate': '01-01-2020',\n                'endDate': '12-31-2001'\n            }\n        ],\n        'layers': [\n            {\n                'product': 'MOD13Q1.061',\n                'layer': '_250m_16_days_NDVI'\n            }\n        ],\n        # Need subdivisions as json, not as a string\n        \"geo\": json.loads(gdf.envelope.to_json()), \n        \"output\": {\n            \"format\": {\"type\": \"geotiff\"}, \n            \"projection\": \"geographic\"\n        }\n    }\n}\n\n# Submit the task request\ntask_response = requests.post(\n    'https://appeears.earthdatacloud.nasa.gov/api/task', \n    json=task, \n    headers={'Authorization': auth_header})\n\n# We need the task ID for later\ntask_id = task_response.json()['task_id'] \n\n\n\nWait for the download preparation task to complete\n\nstatus = 'initializing'\nwhile status != 'done':\n    # Wait 20 seconds in between status checks\n    if status != 'initializing':\n        time.sleep(20)\n\n    # Check status\n    status_response = requests.get(\n        'https://appeears.earthdatacloud.nasa.gov/api/status/{}'\n        .format(task_id), \n        headers={'Authorization': auth_header})\n    \n    # Update status\n    if 'progress' in status_response.json():\n        status = status_response.json()['progress']['summary']\n    elif 'status' in status_response.json():\n        status = status_response.json()['status']\n    print(status)\n\n\n\nDownload files\n\n\n# Get file download information\nbundle_response = requests.get(\n    'https://appeears.earthdatacloud.nasa.gov/api/bundle/{}'\n    .format(task_id),\n    headers={'Authorization': auth_header}\n)\nfiles = bundle_response.json()['files']\n\n'{} files available for download'.format(len(files))\n\n# Download files\nfor file_info in files:\n    # Get a stream to the bundle file\n    response = requests.get( \n        'https://appeears.earthdatacloud.nasa.gov/api/bundle/{}/{}'\n        .format(task_id, file_info['file_id']),  \n        headers={'Authorization': auth_header}, \n        allow_redirects=True,\n        stream=True\n    ) \n\n    # Create a destination directory to store the file in\n    filepath = os.path.join(nd_ndvi_dir, file_info['file_name'])\n    if not os.path.exists(os.path.dirname(filepath)):\n        os.makedirs(os.path.dirname(filepath))\n\n    # Write the file to the destination directory\n    print('Downloading file {}'.format(filepath))\n    with open(filepath, 'wb') as f:\n        for data in response.iter_content(chunk_size=8192):\n            f.write(data)"
  },
  {
    "objectID": "notebooks/04-air-quality/air-quality.html#putting-it-together-working-with-multi-file-raster-datasets-in-python",
    "href": "notebooks/04-air-quality/air-quality.html#putting-it-together-working-with-multi-file-raster-datasets-in-python",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "Putting it together: Working with multi-file raster datasets in Python",
    "text": "Putting it together: Working with multi-file raster datasets in Python\nNow you need to load all the downloaded files into Python. Let‚Äôs start by getting all the file names. You will also need to extract the date from the filename. Check out the lesson on getting information from filenames in the textbook.\n\nGOTCHA ALERT: glob doesn‚Äôt necessarily find files in the order you would expect. Make sure to sort your file names like it says in the textbook.\n\n\n# BEGIN SOLUTION\n# Get list of NDVI tif file paths\nndvi_paths = sorted(glob(os.path.join(data_dir, '*', '*NDVI*.tif')))\n# END SOLUTION\n\n\nRepeating tasks in Python\nNow you should have over 100 files! For each file, you need to: * Filter only files from the summer months, where irrigation makes the most difference * Load the file in using the rioxarray library * Get the date from the file name * Add the date as a dimension coordinate * Give your data variable a name * Divide by the scale factor of 10000\nYou don‚Äôt want to write out the code for each file! That‚Äôs a recipe for copy pasta. Luckily, Python has tools for doing similar tasks repeatedly. In this case, you‚Äôll use one called a for loop.\nThere‚Äôs some code below that uses a for loop in what is called an accumulation pattern to process each file. That means that you will save the results of your processing to a list each time you process the files, and then merge all the arrays in the list.\nYour task is to: * Look at the file names. How many characters from the end is the date? * Replace any required variable names with your chosen variable names * Define the summer_months variable to include the correct months * Change the scale_factor variable to be the correct scale factor for this NDVI dataset (HINT: NDVI should range between 0 and 1) * Using indices or regular\n\nsummer_months = []\nscale_factor = 1\ndoy_start = -1\ndoy_end = -1\n# BEGIN SOLUTION\nsummer_months = ['June', 'July', 'August']\nscale_factor = 10000\ndoy_start = -19\ndoy_end = -12\n# END SOLUTION\nndvi_das = []\nfor ndvi_path in ndvi_paths:\n    # Get date from file name\n    doy = ndvi_path[doy_start:doy_end]\n    date = pd.to_datetime(doy, format='%Y%j')\n\n    # Skip non-summer months\n    if not (date.month_name() in summer_months):\n        continue\n\n    # Open dataset\n    da = rxr.open_rasterio(ndvi_path, masked=True).squeeze()\n\n    # Add date dimension and clean up metadata\n    da = da.assign_coords({'date': date})\n    da = da.expand_dims({'date': 1})\n    da.name = 'NDVI'\n\n    # Multiple by scale factor\n    da = da / scale_factor\n\n    # Prepare for concatenation\n    ndvi_das.append(da)\n\nlen(ndvi_das)\n# END SOLUTION\n\nNext, stack your arrays by date into a time series using the xr.combine_by_coords() function. You will have to tell it which dimension you want to stack your data in.\n\n# BEGIN SOLUTION\nndvi_da = xr.combine_by_coords(ndvi_das, coords=['date'])\nndvi_da\n# END SOLUTION\n\n\n\nPlot the change in NDVI spatially\nComplete the following: * Select data from 2012 to 2022 * Take the temporal mean (over the date, not spatially) * Get the NDVI variable (should be a DataArray, not a Dataset) * Repeat for the data from 2002 to 2012 * Subtract the 2002-2012 decade from the 2012-2022 decade * Plot the result using a diverging color map like cmap=plt.cm.PiYG\n\nThere are different types of color maps for different types of data. In this case, we want decreases to be a different color from increases, so we use a diverging color map. Check out available colormaps in the matplotlib documentation.\n\nüå∂ For an extra challenge, add the Gila River Reservation boundary to the plot\n\n# BEGIN SOLUTION\nndvi_diff = (\n    ndvi_da\n        .sel(date=slice('2012', '2022'))\n        .mean('date')\n        .NDVI \n   - ndvi_da\n        .sel(date=slice('2002', '2012'))\n        .mean('date')\n        .NDVI \n)\nndvi_diff.plot(cmap=plt.cm.PiYG, robust=True)\ngila_gdf.plot(ax=plt.gca(), facecolor='none', edgecolor='black')\n# END SOLUTION"
  },
  {
    "objectID": "notebooks/04-air-quality/air-quality.html#your-turn-repeat-this-workflow-in-a-different-time-and-place.",
    "href": "notebooks/04-air-quality/air-quality.html#your-turn-repeat-this-workflow-in-a-different-time-and-place.",
    "title": "Reclaiming Water Rights on the Gila River",
    "section": "Your turn! Repeat this workflow in a different time and place.",
    "text": "Your turn! Repeat this workflow in a different time and place.\nIt‚Äôs not just water rights that affect NDVI! You could look at: * Recovery after a national disaster, like a wildfire or hurricane * The effects of drought on crop health * Deforestation\nYou can even choose a different dataset, like Landsat, and/or a different spectral index. Check out some other ways to enhance images and highlight different phenomena"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html",
    "href": "notebooks/01b-get-started-api/get-started-api.html",
    "title": "Get started with open reproducible science! (API version)",
    "section": "",
    "text": "Open reproducible science makes scientific methods, data and outcomes available to everyone. That means that everyone who wants should be able to find, read, understand, and run your workflows for themselves.\n\n\nImage from https://www.earthdata.nasa.gov/esds/open-science/oss-for-eso-workshops\n\nFew if any science projects are 100% open and reproducible (yet!). However, members of the open science community have developed open source tools and practices that can help you move toward that goal. You will learn about many of those tools in the Intro to Earth Data Science textbook. Don‚Äôt worry about learning all the tools at once ‚Äì we‚Äôve picked a few for you to get started with.\nWhat does open reproducible science mean to you?\n\n\n\n Create a new Markdown cell below this one using the + Markdown button in the upper left.\n In the new cell, answer the following questions using a numbered list in Markdown:\n\nIn 1-2 sentences, define open reproducible science.\nIn 1-2 sentences, choose one of the open source tools that you have learned about (i.e.¬†Shell, Git/GitHub, Jupyter Notebook, Python) and explain how it supports open reproducible science."
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#human-readable-and-machine-readable",
    "href": "notebooks/01b-get-started-api/get-started-api.html#human-readable-and-machine-readable",
    "title": "Get started with open reproducible science! (API version)",
    "section": " Human-readable and Machine-readable",
    "text": "Human-readable and Machine-readable\n Create a new Markdown cell below this one using the ESC + b keyboard shortcut.\n In the new cell, answer the following question in a Markdown quote:\n\nIn 1-2 sentences, does this Jupyter Notebook file have a machine-readable name? Explain your answer."
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#readable-well-documented-scientific-workflows-are-easier-to-reproduce",
    "href": "notebooks/01b-get-started-api/get-started-api.html#readable-well-documented-scientific-workflows-are-easier-to-reproduce",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Readable, well-documented scientific workflows are easier to reproduce",
    "text": "Readable, well-documented scientific workflows are easier to reproduce\nAs the comic below suggests, code that is hard to read is also hard to get working. We refer to code that is easy to read as clean code.\n\n\n\nAnd because if you just leave it there, it‚Äôs going to start contaminating things downstream even if no one touches it directly. (from [XKCD](https://xkcd.com/2138/))\n\n\n\n\n\n\n\n\n In the prompt below, list 3 things you can do to write clean code, and then list 3 more advantages of doing so.\n\n\n\n\nEdit the text below. You may have to double click.\nYou can use examples from the textbook, or come up with your own.\nUse Markdown to format your list.\n\n\n\n\nI can write clean code by: YOUR ANSWER HERE\nAdvantages of clean code include: YOUR ANSWER HERE"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#what-the-fork-who-wrote-this",
    "href": "notebooks/01b-get-started-api/get-started-api.html#what-the-fork-who-wrote-this",
    "title": "Get started with open reproducible science! (API version)",
    "section": "What the fork?! Who wrote this?",
    "text": "What the fork?! Who wrote this?\nBelow is a scientific Python workflow. But something‚Äôs wrong ‚Äì The code won‚Äôt run! Your task is to follow the instructions below to clean and debug the Python code below so that it runs.\n\n\n\n\n\n\nTip\n\n\n\nDon‚Äôt worry if you can‚Äôt solve every bug right away. We‚Äôll get there! The most important thing is to identify problems with the code and write high-quality GitHub Issues\n\n\nAt the end, you‚Äôll repeat the workflow for a location and measurement of your choosing.\nAlright! Let‚Äôs clean up this code. First things first‚Ä¶\n\n\n\n\n\n\n Machine-readable file names\n\n\n\nRename this notebook if necessary with an expressive and machine-readable file name"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#python-packages-let-you-use-code-written-by-experts-around-the-world",
    "href": "notebooks/01b-get-started-api/get-started-api.html#python-packages-let-you-use-code-written-by-experts-around-the-world",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Python packages let you use code written by experts around the world",
    "text": "Python packages let you use code written by experts around the world\nBecause Python is open source, lots of different people and organizations can contribute (including you!). Many contributions are in the form of packages which do not come with a standard Python download.\n\n\n\n\n\n\n Read more\n\n\n\nPackages need to be installed and imported.\n\n\nIn the cell below, someone was trying to import the pandas package, which helps us to work with tabular data such as comma-separated value or csv files.\n\n\n\n\n\n\n\n Your task\n\n\n\n\nCorrect the typo below to properly import the pandas package under its alias pd.\nRun the cell to import pandas\n\n\n\n\n\n# Import pandas\nimport pandsa as pd\n\n\n\nSee our solution!\n# Import pandas\nimport pandas as pd\n\n\nOnce you have run the cell above and imported pandas, run the cell below. It is a test cell that will tell you if you completed the task successfully. If a test cell isn‚Äôt working the way you expect, check that you ran your code immediately before running the test.\n\n# DO NOT MODIFY THIS TEST CELL\npoints = 0\ntry:\n    pd.DataFrame()\n    points += 5\n    print('\\u2705 Great work! You correctly imported the pandas library.')\nexcept:\n    print('\\u274C Oops - pandas was not imported correctly.')\nprint('You earned {} of 5 points for importing pandas'.format(points))"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#there-are-more-earth-observation-data-online-than-any-one-person-could-ever-look-at",
    "href": "notebooks/01b-get-started-api/get-started-api.html#there-are-more-earth-observation-data-online-than-any-one-person-could-ever-look-at",
    "title": "Get started with open reproducible science! (API version)",
    "section": "There are more Earth Observation data online than any one person could ever look at",
    "text": "There are more Earth Observation data online than any one person could ever look at\nNASA‚Äôs Earth Observing System Data and Information System (EOSDIS) alone manages over 9PB of data. 1 PB is roughly 100 times the entire Library of Congress (a good approximation of all the books available in the US). It‚Äôs all available to you once you learn how to download what you want.\nHere we‚Äôre using the NOAA National Centers for Environmental Information (NCEI) Access Data Service application progamming interface (API) to request data from their web servers. We will be using data collected as part of the Global Historical Climatology Network daily (GHCNd) from their Climate Data Online library program at NOAA.\nFor this example we‚Äôre requesting daily summary data in Boulder, CO (station ID USC00050848) located on the NOAA Campus (39.99282¬∞, -105.26683¬∞).\n\n\n\n\n\n\n\n Your task:\n\n\n\n\nResearch the Global Historical Climatology Network - Daily data source.\nIn the cell below, write a 2-3 sentence description of the data source. You should describe:\n\nwho takes the data\nwhere the data were taken\nwhat the maximum temperature units are\nhow the data are collected\n\nInclude a citation of the data (HINT: See the ‚ÄòData Citation‚Äô tab on the GHCNd overview page).\n\n\n\n\n\nYOUR DATA DESCRIPTION AND CITATION HERE üõéÔ∏è"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#you-can-access-ncei-ghcnd-data-from-the-internet-using-its-api",
    "href": "notebooks/01b-get-started-api/get-started-api.html#you-can-access-ncei-ghcnd-data-from-the-internet-using-its-api",
    "title": "Get started with open reproducible science! (API version)",
    "section": "You can access NCEI GHCNd Data from the internet using its API üñ•Ô∏è üì° üñ•Ô∏è",
    "text": "You can access NCEI GHCNd Data from the internet using its API üñ•Ô∏è üì° üñ•Ô∏è\nThe cell below contains the URL for the data you will use in this part of the notebook. We created this URL by generating what is called an API endpoint using the NCEI API documentation.\n\n\n\n\n\n\nNote\n\n\n\nAn application programming interface (API) is a way for two or more computer programs or components to communicate with each other. It is a type of software interface, offering a service to other pieces of software (Wikipedia).\n\n\nHowever, we still have a problem - we can‚Äôt get the URL back later on because it isn‚Äôt saved in a variable. In other words, we need to give the url a name so that we can request in from Python later (sadly, Python has no ‚Äòhey what was that thingy I typed yesterday?‚Äô function).\n\n\n\n\n\n\n Read more\n\n\n\nCheck out the textbook section on variables\n\n\n\n\n\n\n\n\n Your task\n\n\n\n\nPick an expressive variable name for the URL\n\nHINT: click on the Variables button up top to see all your variables. Your new url variable will not be there until you define it and run the code\n\nReformat the URL so that it adheres to the 79-character PEP-8 line limit\n\nHINT: You should see two vertical lines in each cell - don‚Äôt let your code go past the second line\n\nAt the end of the cell where you define your url variable, call your variable (type out its name) so it can be tested.\n\n\n\n\nstuff23 = ('https://www.ncei.noaa.gov/access/services/da'\n'ta/v1?dataset=daily-summaries&dataTypes=TOBS,PRCP&stations=USC00050848&startDate=1893-10-01&endDate=2024-02-18&includeStationName=true&includeStation'\n'Location=1&units=standard')\nstuff23\n\n\n\nSee our solution!\nboulder_url = (\n    'https://www.ncei.noaa.gov/access/services/data/v1'\n    '?dataset=daily-summaries'\n    '&dataTypes=TOBS,PRCP'\n    '&stations=USC00050848'\n    '&startDate=1893-10-01'\n    '&endDate=2024-02-18'\n    '&includeStationName=true'\n    '&includeStationLocation=1'\n    '&units=standard')\nboulder_url\n\n\n\n# DO NOT MODIFY THIS TEST CELL\nresp_url = _\npoints = 0\n\nif type(resp_url)==str:\n    points += 3\n    print('\\u2705 Great work! You correctly called your url variable.')\nelse:\n    print('\\u274C Oops - your url variable was not called correctly.')\n\nif len(resp_url)==218:\n    points += 3\n    print('\\u2705 Great work! Your url is the correct length.')\nelse:\n    print('\\u274C Oops - your url variable is not the correct length.')\n\nprint('You earned {} of 6 points for defining a url variable'.format(points))"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#download-and-get-started-working-with-ncei-data",
    "href": "notebooks/01b-get-started-api/get-started-api.html#download-and-get-started-working-with-ncei-data",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Download and get started working with NCEI data",
    "text": "Download and get started working with NCEI data\nThe pandas library you imported can download data from the internet directly into a type of Python object called a DataFrame. In the code cell below, you can see an attempt to do just this. But there are some problems‚Ä¶\n\n\n\n\n\n\n You‚Äôre ready to fix some code!\n\n\n\nYour task is to:\n\nLeave a space between the # and text in the comment and try making the comment more informative\nMake any changes needed to get this code to run. HINT: The my_url variable doesn‚Äôt exist - you need to replace it with the variable name you chose.\nModify the .read_csv() statement to include the following parameters:\n\nindex_col='DATE' ‚Äì this sets the DATE column as the index. Needed for subsetting and resampling later on\nparse_dates=True ‚Äì this lets python know that you are working with time-series data, and values in the indexed column are date time objects\nna_values=['NaN'] ‚Äì this lets python know how to handle missing values\n\nClean up the code by using expressive variable names, expressive column names, PEP-8 compliant code, and descriptive comments\n\n\n\n\nMake sure to call your DataFrame by typing it‚Äôs name as the last line of your code cell Then, you will be able to run the test cell below and find out if your answer is correct.\n\n\nboulder_df = pd.read_csv(\n  boulder_url,\n  index_col='something')\nboulder_df\n\n\n\nSee our solution!\n# Download the Boulder climate data\nboulder_df = pd.read_csv(\n  boulder_url,\n  index_col='DATE',\n  parse_dates=True,\n  na_values=['NaN'])\nboulder_df\n\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nif isinstance(tmax_df_resp, pd.DataFrame):\n    points += 1\n    print('\\u2705 Great work! You called a DataFrame.')\nelse:\n    print('\\u274C Oops - make sure to call your DataFrame for testing.')\n\nprint('You earned {} of 2 points for downloading data'.format(points))\n\n\nHINT: Check out the type() function below - you can use it to check that your data is now in DataFrame type object\n\n\n# Check that the data was imported into a pandas DataFrame\ntype(boulder_df)\n\n\n\n\n\n\n\n Clean up your DataFrame\n\n\n\nUse double brackets to only select the columns you want in your DataFrame\n\n\n\nMake sure to call your DataFrame by typing it‚Äôs name as the last line of your code cell Then, you will be able to run the test cell below and find out if your answer is correct.\n\n\nboulder_df = boulder_df[['some_col', 'another_col']]\nboulder_df\n\n\n\nSee our solution!\n# Clean up the DataFrame\nboulder_df = boulder_df[['PRCP', 'TOBS']]\nboulder_df\n\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nsummary = [round(val, 2) for val in tmax_df_resp.mean().values]\nif summary == [0.05, 54.53]:\n    points += 4\n    print('\\u2705 Great work! You correctly downloaded data.')\nelse:\n    print('\\u274C Oops - your data are not correct.')\nprint('You earned {} of 5 points for downloading data'.format(points))"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#plot-the-precpitation-column-prcp-vs-time-to-explore-the-data",
    "href": "notebooks/01b-get-started-api/get-started-api.html#plot-the-precpitation-column-prcp-vs-time-to-explore-the-data",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Plot the precpitation column (PRCP) vs time to explore the data",
    "text": "Plot the precpitation column (PRCP) vs time to explore the data\nPlotting in Python is easy, but not quite this easy:\n\nboulder_df.plot()\n\nYou‚Äôll always need to add some instructions on labels and how you want your plot to look.\n\n\n\n\n\n\nImportant\n\n\n\n\nChange dataframe to your DataFrame name.\nChange y= to the name of your observed temperature column name.\nUse the title, ylabel, and xlabel parameters to add key text to your plot.\nAdjust the size of your figure using figsize=(x,y) where x is figure width and y is figure height\n\n\nHINT: labels have to be a type in Python called a string. You can make a string by putting quotes around your label, just like the column names in the sample code (eg y='TOBS').\n\n\n\n\n# Plot the temperature vs time\nyour_dataframe_name.plot(y='temperature_col_name', figsize=(10,6))\n\n\n\n\n\n\n\n Your task: Playing with code\n\n\n\n\nReplace dataframe with the name of your dataframe whenever it appears.\nReplace the title and axis labels with something more appropriate for this data.\nRun the code below.\n\n\n\n\n# Plot the data using .plot\nboulder_df.plot(\n    y='the_precipitation_column',\n    title='Title Goes Here',\n    xlabel='Horizontal Axis Label Goes Here',\n    ylabel='Vertical Axis Label Goes Here')\n\n\n\nSee our solution!\n# Plot the data using .plot\nboulder_df.plot(\n    y='PRCP',\n    title='Daily Precipitation in Boulder, CO',\n    xlabel='Date',\n    ylabel='Precipitation (mm)')\n\n\n\n\n\n\n\n\n Want an EXTRA CHALLENGE?\n\n\n\nThere are many other things you can do to customize your plot. Take a look at the pandas plotting galleries and the documentation of plot to see if there‚Äôs other changes you want to make to your plot. Some possibilities include:\n\nRemove the legend since there‚Äôs only one data series\nIncrease the figure size\nIncrease the font size\nChange the colors\nUse a bar graph instead (usually we use lines for time series, but since this is annual it could go either way)\nAdd a trend line\n\nNot sure how to do any of these? Try searching the internet, or asking an AI!\n\n\n\n\n\n\n\n\n\n Convert units\n\n\n\nModify the code below to add a column that includes temperature in Celsius. The code below was written by your colleague. Can you fix this so that it correctly calculates temperature in Celsius and adds a new column?\n\n\n\n# Convert to celcius\nboulder_df['TCel'] = boulder_df['temperature_col_name'] - 32 * 5 / 9\nboulder_df\n\n\n\nSee our solution!\n# Convert to celcius\nboulder_df['TCel'] = (boulder_df['TOBS'] - 32) * 5 / 9\nboulder_df\n\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nif isinstance(tmax_df_resp, pd.DataFrame):\n    points += 1\n    print('\\u2705 Great work! You called a DataFrame.')\nelse:\n    print('\\u274C Oops - make sure to call your DataFrame for testing.')\n\nsummary = [round(val, 4) for val in tmax_df_resp.mean().values]\nif summary == [0.0543, 54.5313, 12.5174]:\n    points += 4\n    print('\\u2705 Great work! You correctly converted to Celcius.')\nelse:\n    print('\\u274C Oops - your data are not correct.')\nprint('You earned {} of 5 points for converting to Celcius'.format(points))\n\n\n\n\n\n\n\n Want an EXTRA CHALLENGE?\n\n\n\n\nAs you did above, rewrite the code to be more expressive\nUsing the code below as a framework, write and apply a function that converts to Celcius. &gt; Functions let you reuse code you have already written\nYou should also rewrite this function and parameter names to be more expressive.\n\n\n\n\ndef a_function(a_parameter):\n    \"\"\"Convert temperature to Celcius\"\"\"\n    return a_parameter # Put your equation in here\n\ndataframe['celcius_column'] = dataframe['fahrenheit_column'].apply(convert)\n\n\n\nSee our solution!\ndef convert_to_celcius(fahrenheit):\n    \"\"\"Convert temperature to Celcius\"\"\"\n    return (fahrenheit - 32) * 5 / 9\n\nboulder_df['TCel'] = boulder_df['TOBS'].apply(convert_to_celcius)"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#subsetting-and-resampling",
    "href": "notebooks/01b-get-started-api/get-started-api.html#subsetting-and-resampling",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Subsetting and Resampling",
    "text": "Subsetting and Resampling\nOften when working with time-series data you may want to focus on a shorter window of time, or look at weekly, monthly, or annual summaries to help make the analysis more manageable.\n\n\n\n\n\n\n Read more\n\n\n\nRead more about subsetting and resampling time-series data in our Learning Portal.\n\n\nFor this demonstration, we will look at the last 30-40 years worth of data and resample to explore a summary from each year that data were recorded.\n\n\n\n\n\n\n Your task\n\n\n\n\nReplace start-year and end-year with the years that begin and end the window of time that you would like to explore\nReplace dataframe with the name of your data\nReplace new_variable_name with something more expressive\nCall your new variable\nRun the cell\n\n\n\n\n# Subset the data to look at 1983-2023\nboulder_1983_2023 = boulder_df['1983':'2023']\nboulder_1983_2023\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nif isinstance(tmax_df_resp, pd.DataFrame):\n    points += 1\n    print('\\u2705 Great work! You called a DataFrame.')\nelse:\n    print('\\u274C Oops - make sure to call your DataFrame for testing.')\n\nsummary = [round(val, 2) for val in tmax_df_resp.mean().values]\nif summary == [0.06, 55.67, 13.15]:\n    points += 4\n    print('\\u2705 Great work! You correctly converted to Celcius.')\nelse:\n    print('\\u274C Oops - your data are not correct.')\nprint('You earned {} of 5 points for converting to Celcius'.format(points))"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#now-we-are-ready-to-calculate-annual-statistics",
    "href": "notebooks/01b-get-started-api/get-started-api.html#now-we-are-ready-to-calculate-annual-statistics",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Now we are ready to calculate annual statistics",
    "text": "Now we are ready to calculate annual statistics\nHere you will resample the 2013-2023 data to look the annual mean values.\n\n\n\n\n\n\n Resample your data\n\n\n\n\nReplace new_variable_name with the variable you created in the cell above where you subset the data\nReplace 'TIME' with a 'W', 'M', or 'Y' depending on whether you‚Äôre doing a weekly, monthly, or yearly summary\nReplace STAT with a sum, min, max, or mean depending on what kind of statistic you‚Äôre interested in calculating.\nReplace resampled_data with a more expressive variable name\nCall your new variable\nRun the cell\n\n\n\n\n# Resample the data to look at yearly mean values\nboulder_yearly_mean = boulder_1983_2023.resample('Y').mean()\nboulder_yearly_mean\n\n\n\n\n\n\n\n Plot your resampled data\n\n\n\n\n\n\n\n# Plot mean annual temperature values\n\n\n\n\n\n\n\n\n Describe your plot\n\n\n\nWe like to use an approach called ‚ÄúAssertion-Evidence‚Äù for presenting scientific results. There‚Äôs a lot of video tutorials and example talks available on the Assertion-Evidence web page. The main thing you need to do now is to practice writing a message or headline rather than descriptions or topic sentences for the plot you just made (what they refer to as ‚Äúvisual evidence‚Äù).\nFor example, it would be tempting to write something like ‚ÄúA plot of maximum annual temperature in Boulder, Colorado over time (1983-2023)‚Äù. However, this doesn‚Äôt give the reader anything to look at, or explain why we made this particular plot (we know, you made this one because we told you to)\nSome alternatives for different plots of Boulder temperature that are more of a starting point for a presentation or conversation are:\n\nBoulder, CO experienced cooler than average temperatures in 1995\nTemperatures in Bouler, CO appear to be on the rise over the past 40 years\nMaximum annual temperatures in Boulder, CO are becoming more variable over the previous 40 years\n\nWe could back up some of these claims with further analysis included later on, but we want to make sure that our audience has some guidance on what to look for in the plot."
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#your-boulder-plot-headline-here",
    "href": "notebooks/01b-get-started-api/get-started-api.html#your-boulder-plot-headline-here",
    "title": "Get started with open reproducible science! (API version)",
    "section": "YOUR BOULDER PLOT HEADLINE HERE üì∞ üóûÔ∏è üìª",
    "text": "YOUR BOULDER PLOT HEADLINE HERE üì∞ üóûÔ∏è üìª\nDescribe your plot in this cell in 2-3 sentences\n\n\n\nWriting bear\n\n\n\nImage credit: https://www.craiyon.com/image/OAbZtyelSoS7FdGko6hvQg"
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#your-turn-pick-a-new-location-andor-measurement-to-plot",
    "href": "notebooks/01b-get-started-api/get-started-api.html#your-turn-pick-a-new-location-andor-measurement-to-plot",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Your turn: pick a new location and/or measurement to plot üåè üìà",
    "text": "Your turn: pick a new location and/or measurement to plot üåè üìà\nBelow (or in a new notebook!), recreate the workflow you just did in a place that interests you OR with a different measurement. See the instructions above to adapt the URL that we created for Boulder, CO using the NCEI API. You will need to make your own new Markdown and Code cells below this one, or create a new notebook."
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#congratulations-youre-almost-done-with-this-coding-challenge-now-make-sure-that-your-code-is-reproducible",
    "href": "notebooks/01b-get-started-api/get-started-api.html#congratulations-youre-almost-done-with-this-coding-challenge-now-make-sure-that-your-code-is-reproducible",
    "title": "Get started with open reproducible science! (API version)",
    "section": "Congratulations, you‚Äôre almost done with this coding challenge ü§© ‚Äì now make sure that your code is reproducible",
    "text": "Congratulations, you‚Äôre almost done with this coding challenge ü§© ‚Äì now make sure that your code is reproducible\n\n\nImage source: https://dfwurbanwildlife.com/2018/03/25/chris-jacksons-dfw-urban-wildlife/snow-geese-galore/\n\n\n\n\n\n\n\n Your task\n\n\n\n\nIf you didn‚Äôt already, go back to the code you modified about and write more descriptive comments so the next person to use this code knows what it does.\nMake sure to Restart and Run all up at the top of your notebook. This will clear all your variables and make sure that your code runs in the correct order. It will also export your work in Markdown format, which you can put on your website."
  },
  {
    "objectID": "notebooks/01b-get-started-api/get-started-api.html#bonus-create-a-shareable-markdown-of-your-work",
    "href": "notebooks/01b-get-started-api/get-started-api.html#bonus-create-a-shareable-markdown-of-your-work",
    "title": "Get started with open reproducible science! (API version)",
    "section": "BONUS: Create a shareable Markdown of your work",
    "text": "BONUS: Create a shareable Markdown of your work\nBelow is some code that you can run that will save a Markdown file of your work that is easily shareable and can be uploaded to GitHub Pages. You can use it as a starting point for writing your portfolio post!\n\n%%capture\n%%bash\njupyter nbconvert 01-dsc-open-science.ipynb --to markdown"
  },
  {
    "objectID": "notebooks/00-header-nb.html",
    "href": "notebooks/00-header-nb.html",
    "title": "It‚Äôs another STARS 2023 Earth Data Science Workflow!",
    "section": "",
    "text": "This notebook contains your next earth data science coding challenge! Before we get started, make sure to read or review the guidelines below. These will help make sure that your code is readable and reproducible.\n\n\n\n\nImage source: https://alaskausfws.medium.com/whats-big-and-brown-and-loves-salmon-e1803579ee36\n\nThese are the most common issues that will keep you from getting started and delay your code review:\n\nWhen you try to run some code, you may be prompted to select a kernel.\n\nThe kernel refers to the version of Python you are using\nYou should use the base kernel, which should be the default option.\nYou can also use the Select Kernel menu in the upper right to select the base kernel\n\nBefore you commit your work, make sure it runs reproducibly by clicking:\n\nRestart (this button won‚Äôt appear until you‚Äôve run some code), then\nRun All\n\n\n\n\n\n\n\nFormat all cells prior to submitting (right click on your code).\nUse expressive names for variables so you or the reader knows what they are.\nUse comments to explain your code ‚Äì e.g.¬†\n# This is a comment, it starts with a hash sign\n\n\n\n\n\n\n\nSource: https://xkcd.com/833\n\n\nMake sure each plot has: * A title that explains where and when the data are from * x- and y- axis labels with units where appropriate * A legend where appropriate\n\n\n\nWe use the following icons to let you know when you need to change something to complete the challenge: * üíª means you need to write or edit some code.\n\nüìñ indicates recommended reading\n‚úé marks written responses to questions\nüå∂ is an optional extra challenge"
  },
  {
    "objectID": "notebooks/00-header-nb.html#dont-get-caught-by-these-jupyter-notebook-gotchas",
    "href": "notebooks/00-header-nb.html#dont-get-caught-by-these-jupyter-notebook-gotchas",
    "title": "It‚Äôs another STARS 2023 Earth Data Science Workflow!",
    "section": "",
    "text": "Image source: https://alaskausfws.medium.com/whats-big-and-brown-and-loves-salmon-e1803579ee36\n\nThese are the most common issues that will keep you from getting started and delay your code review:\n\nWhen you try to run some code, you may be prompted to select a kernel.\n\nThe kernel refers to the version of Python you are using\nYou should use the base kernel, which should be the default option.\nYou can also use the Select Kernel menu in the upper right to select the base kernel\n\nBefore you commit your work, make sure it runs reproducibly by clicking:\n\nRestart (this button won‚Äôt appear until you‚Äôve run some code), then\nRun All"
  },
  {
    "objectID": "notebooks/00-header-nb.html#check-your-code-to-make-sure-its-clean-and-easy-to-read",
    "href": "notebooks/00-header-nb.html#check-your-code-to-make-sure-its-clean-and-easy-to-read",
    "title": "It‚Äôs another STARS 2023 Earth Data Science Workflow!",
    "section": "",
    "text": "Format all cells prior to submitting (right click on your code).\nUse expressive names for variables so you or the reader knows what they are.\nUse comments to explain your code ‚Äì e.g.¬†\n# This is a comment, it starts with a hash sign"
  },
  {
    "objectID": "notebooks/00-header-nb.html#label-and-describe-your-plots",
    "href": "notebooks/00-header-nb.html#label-and-describe-your-plots",
    "title": "It‚Äôs another STARS 2023 Earth Data Science Workflow!",
    "section": "",
    "text": "Source: https://xkcd.com/833\n\n\nMake sure each plot has: * A title that explains where and when the data are from * x- and y- axis labels with units where appropriate * A legend where appropriate"
  },
  {
    "objectID": "notebooks/00-header-nb.html#icons-how-to-use-this-notebook",
    "href": "notebooks/00-header-nb.html#icons-how-to-use-this-notebook",
    "title": "It‚Äôs another STARS 2023 Earth Data Science Workflow!",
    "section": "",
    "text": "We use the following icons to let you know when you need to change something to complete the challenge: * üíª means you need to write or edit some code.\n\nüìñ indicates recommended reading\n‚úé marks written responses to questions\nüå∂ is an optional extra challenge"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to the ESIIL Learning Portal!",
    "section": "",
    "text": "Welcome to the ESIIL Learning Portal!\nExplore textbooks:\n\nIntroduction to Earth Data Science\nESIIL Data Short Course\nESIIL STARS Textbook"
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/05-map.html",
    "href": "pages/03-git-github/03-github-portfolio/05-map.html",
    "title": "Add a map to your website",
    "section": "",
    "text": "You‚Äôll need to start by importing some libraries to have access to all the code you need.\nTo run code in Codespaces, click on the play button in the upper left corner of the code you want to run. You may be asked to ‚ÄúSelect a kernel‚Äù. If you press Return or click on base up at the top, that should select the default kernel.\n\n# Work with vector data\nimport geopandas as gpd\n\n# Save maps and plots to files\nimport holoviews as hv\n# Create interactive maps and plots\nimport hvplot.pandas\n\n# Search for locations by name - this might take a moment\nfrom osmnx import features as osm\n\n\n\n\nYou can use the pyrosm package to download and search for spatial vector data in your area, or anywhere around the world.\nIn this case, we‚Äôre looking for the location of the United Tribes Technical College campus in North Dakota. The address in here, 'United Tribes Technical College, Bismarck, ND, United States', does not have to be complete or exact, but it should be specific enough to narrow it down. We are also specifying that we want it to be tagges as a 'amenity' type, specifically a 'college' You might have to try a couple different searches with different addresses and/or tags to get the address you want, just like if you are using a map website or app.\n\n# Search for United Tribes Technical College\nuttc_gdf = osm.features_from_address(\n    'United Tribes Technical College, Bismarck, ND, United States',\n    {'amenity': ['college']})\nuttc_gdf\n\n\nuttc_gdf.plot()\n\nWe have a map of the UTTC Campus!\n\n\n\n\n\n\nWarning\n\n\n\nThe Open Street Maps (OSM) database is not always complete. For example, try searching for UTTC with the {'building': True}, and compare it to the map of the UTTC campus on their website. What do you notice?\n\n\n\n\n\nThere are lots of different ways to create maps and plots in Python. Here, we‚Äôre going to use a tool called 'hvplot' and 'geoviews' to create an interactive map, including the online 'EsriImagery' tile source basemap.\n\n# Plot UTTC boundary\nuttc_map = uttc_gdf.reset_index().hvplot(\n    # Givethe map a descriptive title\n    title=\"United Tribes Technical College, Bismarck, ND\",\n    # Add a basemap\n    geo=True, tiles='EsriImagery',\n    # Change the colors\n    fill_color='white', fill_alpha=0.2,\n    line_color='skyblue', line_width=5,\n    # Change the image size\n    frame_width=400, frame_height=400)\n\n# Save the map as a file to put on the web\nhv.save(uttc_map, 'uttc.html')\n\n# Display the map\nuttc_map\n\n\n\n\nIf you are doing this activity on GitHub Codespaces, you will need to download the map you created:\n\nOpen the Folders tab on the left hand side\nRight-click on uttc.html (or whatever you named your file)\nSelect Download...\n\nThis should download your map.\n::: {.content-hidden when-profile=‚Äúnb‚Äù}\n\n\n\nYou are now ready to upload your map to your portfolio repository and place it in your webpage. Because it is HTML and not an image, you will need to use the following HTML to get it on your page:\n&lt;embed type=\"text/html\" src=\"uttc.html\" width=\"600\" height=\"600\"&gt;\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to make the width and height of your embed element larger than the frame_width and frame_height of your plot, or it will get cut off!\n\n\n:::"
  },
  {
    "objectID": "pages/03-git-github/03-github-portfolio/05-map.html#get-started-with-map-making-using-open-sources-tools",
    "href": "pages/03-git-github/03-github-portfolio/05-map.html#get-started-with-map-making-using-open-sources-tools",
    "title": "Add a map to your website",
    "section": "",
    "text": "You‚Äôll need to start by importing some libraries to have access to all the code you need.\nTo run code in Codespaces, click on the play button in the upper left corner of the code you want to run. You may be asked to ‚ÄúSelect a kernel‚Äù. If you press Return or click on base up at the top, that should select the default kernel.\n\n# Work with vector data\nimport geopandas as gpd\n\n# Save maps and plots to files\nimport holoviews as hv\n# Create interactive maps and plots\nimport hvplot.pandas\n\n# Search for locations by name - this might take a moment\nfrom osmnx import features as osm\n\n\n\n\nYou can use the pyrosm package to download and search for spatial vector data in your area, or anywhere around the world.\nIn this case, we‚Äôre looking for the location of the United Tribes Technical College campus in North Dakota. The address in here, 'United Tribes Technical College, Bismarck, ND, United States', does not have to be complete or exact, but it should be specific enough to narrow it down. We are also specifying that we want it to be tagges as a 'amenity' type, specifically a 'college' You might have to try a couple different searches with different addresses and/or tags to get the address you want, just like if you are using a map website or app.\n\n# Search for United Tribes Technical College\nuttc_gdf = osm.features_from_address(\n    'United Tribes Technical College, Bismarck, ND, United States',\n    {'amenity': ['college']})\nuttc_gdf\n\n\nuttc_gdf.plot()\n\nWe have a map of the UTTC Campus!\n\n\n\n\n\n\nWarning\n\n\n\nThe Open Street Maps (OSM) database is not always complete. For example, try searching for UTTC with the {'building': True}, and compare it to the map of the UTTC campus on their website. What do you notice?\n\n\n\n\n\nThere are lots of different ways to create maps and plots in Python. Here, we‚Äôre going to use a tool called 'hvplot' and 'geoviews' to create an interactive map, including the online 'EsriImagery' tile source basemap.\n\n# Plot UTTC boundary\nuttc_map = uttc_gdf.reset_index().hvplot(\n    # Givethe map a descriptive title\n    title=\"United Tribes Technical College, Bismarck, ND\",\n    # Add a basemap\n    geo=True, tiles='EsriImagery',\n    # Change the colors\n    fill_color='white', fill_alpha=0.2,\n    line_color='skyblue', line_width=5,\n    # Change the image size\n    frame_width=400, frame_height=400)\n\n# Save the map as a file to put on the web\nhv.save(uttc_map, 'uttc.html')\n\n# Display the map\nuttc_map\n\n\n\n\nIf you are doing this activity on GitHub Codespaces, you will need to download the map you created:\n\nOpen the Folders tab on the left hand side\nRight-click on uttc.html (or whatever you named your file)\nSelect Download...\n\nThis should download your map.\n::: {.content-hidden when-profile=‚Äúnb‚Äù}\n\n\n\nYou are now ready to upload your map to your portfolio repository and place it in your webpage. Because it is HTML and not an image, you will need to use the following HTML to get it on your page:\n&lt;embed type=\"text/html\" src=\"uttc.html\" width=\"600\" height=\"600\"&gt;\n\n\n\n\n\n\n\nImportant\n\n\n\nMake sure to make the width and height of your embed element larger than the frame_width and frame_height of your plot, or it will get cut off!\n\n\n:::"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html",
    "href": "notebooks/01a-get-started/get-started.html",
    "title": "Get started with open reproducible science!",
    "section": "",
    "text": "(Earth Science Data Systems, 2021)\nOpen reproducible science makes scientific methods, data and outcomes available to everyone. That means that everyone who wants should be able to find, read, understand, and run your workflows for themselves.\nFew if any science projects are 100% open and reproducible (yet!). However, members of the open science community have developed open source tools and practices that can help you move toward that goal. You will learn about many of those tools in the Intro to Earth Data Science textbook. Don‚Äôt worry about learning all the tools at once ‚Äì we‚Äôve picked a few for you to get started with.\n\n\n\n\n\n\n Further reading\n\n\n\nRead our textbook chapter about open reproducible science.\n\n\n\n\n\n\n\n\n What does open reproducible science mean to you?\n\n\n\n Create a new Markdown cell below this one using the + Code button in the upper left.\n In the new cell, answer the following questions using a numbered list in Markdown:\n\nIn 1-2 sentences, define open reproducible science.\nIn 1-2 sentences, choose one of the open source tools that you have learned about (i.e.¬†Shell, Git/GitHub, Jupyter Notebook, Python) and explain how it supports open reproducible science.\n\n\n\n\n\n\n\n\n\n Human-readable and Machine-readable\n\n\n\n Create a new Markdown cell below this one using the ESC + b` keyboard shortcut.\n In the new cell, answer the following question in a Markdown quote:\n\nIn 1-2 sentences, does this Jupyter Notebook file have a machine-readable name? Explain your answer."
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#open-reproducible-science",
    "href": "notebooks/01a-get-started/get-started.html#open-reproducible-science",
    "title": "Get started with open reproducible science!",
    "section": "",
    "text": "(Earth Science Data Systems, 2021)\nOpen reproducible science makes scientific methods, data and outcomes available to everyone. That means that everyone who wants should be able to find, read, understand, and run your workflows for themselves.\nFew if any science projects are 100% open and reproducible (yet!). However, members of the open science community have developed open source tools and practices that can help you move toward that goal. You will learn about many of those tools in the Intro to Earth Data Science textbook. Don‚Äôt worry about learning all the tools at once ‚Äì we‚Äôve picked a few for you to get started with.\n\n\n\n\n\n\n Further reading\n\n\n\nRead our textbook chapter about open reproducible science.\n\n\n\n\n\n\n\n\n What does open reproducible science mean to you?\n\n\n\n Create a new Markdown cell below this one using the + Code button in the upper left.\n In the new cell, answer the following questions using a numbered list in Markdown:\n\nIn 1-2 sentences, define open reproducible science.\nIn 1-2 sentences, choose one of the open source tools that you have learned about (i.e.¬†Shell, Git/GitHub, Jupyter Notebook, Python) and explain how it supports open reproducible science.\n\n\n\n\n\n\n\n\n\n Human-readable and Machine-readable\n\n\n\n Create a new Markdown cell below this one using the ESC + b` keyboard shortcut.\n In the new cell, answer the following question in a Markdown quote:\n\nIn 1-2 sentences, does this Jupyter Notebook file have a machine-readable name? Explain your answer."
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#readable-well-documented-scientific-workflows-are-easier-to-reproduce",
    "href": "notebooks/01a-get-started/get-started.html#readable-well-documented-scientific-workflows-are-easier-to-reproduce",
    "title": "Get started with open reproducible science!",
    "section": "Readable, well-documented scientific workflows are easier to reproduce",
    "text": "Readable, well-documented scientific workflows are easier to reproduce\nAs the comic below suggests, code that is hard to read is also hard to get working. We refer to code that is easy to read as clean code.\n\n\n\nAnd because if you just leave it there, it‚Äôs going to start contaminating things downstream even if no one touches it directly. (from https://xkcd.com/2138/)\n\n\n In the prompt below, list 3 things you can do to write clean code, and then list 3 more advantages of doing so. * Double click on the cell to edit * You can use examples from the textbook, or come up with your own. * Use Markdown to format your list.\n=== BEGIN MARK SCHEME ===\n(1 pt each) demonstrating understanding of clean code practices and advantages\n(2 pt) Correct spelling and grammar\n=== END MARK SCHEME ===\nI can write clean code by: * YOUR ANSWER HERE\nAdvantages of clean code include: * YOUR ANSWER HERE"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#what-the-fork-who-wrote-this",
    "href": "notebooks/01a-get-started/get-started.html#what-the-fork-who-wrote-this",
    "title": "Get started with open reproducible science!",
    "section": "What the fork?! Who wrote this?",
    "text": "What the fork?! Who wrote this?\nBelow is a scientific Python workflow. But something‚Äôs wrong ‚Äì The code won‚Äôt run! Your task is to follow the instructions below to clean and debug the Python code below so that it runs. &gt; Don‚Äôt worry if you can‚Äôt solve every bug right away. We‚Äôll get there! The most important thing is to identify problems with the code and write high-quality GitHub Issues\nAt the end, you‚Äôll repeat the workflow for a location and measurement of your choosing.\n\nAlright! Let‚Äôs clean up this code. First things first‚Ä¶\n Rename this notebook if necessary with an expressive and machine-readable file name"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#python-packages-let-you-use-code-written-by-experts-around-the-world",
    "href": "notebooks/01a-get-started/get-started.html#python-packages-let-you-use-code-written-by-experts-around-the-world",
    "title": "Get started with open reproducible science!",
    "section": "Python packages let you use code written by experts around the world",
    "text": "Python packages let you use code written by experts around the world\nBecause Python is open source, lots of different people and organizations can contribute (including you!). Many contributions are in the form of packages which do not come with a standard Python download. Read more in your textbook: *  Packages need to be installed and imported.\n\n In the cell below, someone was trying to import the pandas package, which helps us to work with tabular data such as comma-separated value or csv files.\n\n Your task ‚Äì uncomment the code in the cell below by removeing the # symbol on the left of line 2, and correct the typo to properly import the pandas package under its alias pd.\n\n#can't get this to work :(\n#import pands as pd\n\n# BEGIN SOLUTION\nimport pandas as pd\n# END SOLUTION\n\nOnce you have run the cell above and imported pandas, run the cell below. It is a test cell that will tell you if you completed the task successfully. If a test cell isn‚Äôt working the way you expect, check that you ran your code immediately before running the test.\n\n# DO NOT MODIFY THIS TEST CELL\npoints = 0\ntry:\n    pd.DataFrame()\n    points += 5\n    print('\\u2705 Great work! You correctly imported the pandas library.')\nexcept:\n    print('\\u274C Oops - pandas was not imported correctly.')\nprint('You earned {} of 5 points for importing pandas'.format(points))"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#there-are-more-earth-observation-data-online-than-any-one-person-could-ever-look-at",
    "href": "notebooks/01a-get-started/get-started.html#there-are-more-earth-observation-data-online-than-any-one-person-could-ever-look-at",
    "title": "Get started with open reproducible science!",
    "section": "There are more Earth Observation data online than any one person could ever look at",
    "text": "There are more Earth Observation data online than any one person could ever look at\nNASA‚Äôs Earth Observing System Data and Information System (EOSDIS) alone manages over 9PB of data. 1 PB is roughly 100 times the entire Library of Congress (a good approximation of all the books available in the US). It‚Äôs all available to you once you learn how to download what you want.\nThe following workflow looks at maximum daily average temperatures over time in Rapid City, South Dakota. This notebook uses data from the National Centers for Environmental Information (NCEI). Check out the NCEI Climate at a Glance website where you can search for more data like this. &gt; Wait a second - what is maximum daily average temperature? NCEI first takes the daily average temperature. Then, they take the annual maximum. You‚Äôll notice these temperatures are a bit lower than we would expect from maxima - that‚Äôs because nighttime temperatures get incorporated into the daily average.\n Your task: 1. Research the Climate at a Glance data source. 2. In the cell below, write a 2-3 sentence description of the data source. You should describe: - who takes the data - where the data were taken - what the maximum temperature units are - how the data are collected. 3. Include a citation of the data (HINT: NCEI has a section for ‚ÄòCiting this page‚Äô, but you will have to select a particular dataset such as City &gt; Time Series).\n===BEGIN MARK SCHEME ===\n‚ÄúClimate at a Glance was developed at the request of NOAA Headquarters for near real-time analysis of monthly temperature and precipitation data across the contiguous U.S. and intended for the study of climate variability‚Ä¶Because these data are primarily intended for the study of climate variability, observations have been adjusted to account for the artificial effects introduced into the climate record by factors such as instrument changes, station relocation, observer practice changes and urbanization.‚Äù\nNOAA National Centers for Environmental information, Climate at a Glance: City Time Series, published February 2023, retrieved on February 26, 2023 from https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/city/time-series\n=== END MARK SCHEME ===\nYOUR DATA DESCRIPTION AND CITATION HERE"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#you-can-access-ncei-climate-at-a-glance-data-from-the-internet-using-its-url",
    "href": "notebooks/01a-get-started/get-started.html#you-can-access-ncei-climate-at-a-glance-data-from-the-internet-using-its-url",
    "title": "Get started with open reproducible science!",
    "section": "You can access NCEI Climate At a Glance Data from the internet using its URL",
    "text": "You can access NCEI Climate At a Glance Data from the internet using its URL\nThe cell below contains the URL for the data you will use in this part of the notebook. We got that URL by right-clicking on the blue CSV download button. You don‚Äôt have to do that just yet ‚Äì this URL is correct! However, we still have a problem - we can‚Äôt get the URL back later on because it isn‚Äôt saved in a variable. In other words, we need to give the url a name so that we can request in from Python later (sadly, Python has no ‚Äòhey what was that thingy I typed earlier?‚Äô function)\n Check out the textbook section on variables\n Your task: 1. Pick an expressive variable name for the URL &gt; HINT: click on the Variables button up top to see all your variables. Your new url variable will not be there until you define it and run the code 2. Reformat the URL so that it adheres to the 79-character PEP-8 line limit &gt; HINT: You should see two vertical lines in each cell - don‚Äôt let your code go past the second line 3. At the end of the cell where you define your url variable, call your variable (type out its name) so it can be tested.\n\n'https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/city/time-series/USW00024090/tmax/ann/2/1949-2023.csv'\n\n# BEGIN SOLUTION\nmy_url = (\n    \"https://www.ncei.noaa.gov/access/monitoring/climate-at-a-glance/\"\n    \"city/time-series/USW00024090/tmax/ann/2/1949-2023.csv\")\nprint(len(my_url))\nmy_url\n# END SOLUTION\n\n\n# DO NOT MODIFY THIS TEST CELL\nresp_url = _\npoints = 0\n\nif type(resp_url)==str:\n    points += 3\n    print('\\u2705 Great work! You correctly called your url variable.')\nelse:\n    print('\\u274C Oops - your url variable was not called correctly.')\n\nif len(resp_url)==117:\n    points += 3\n    print('\\u2705 Great work! Your url is the correct length.')\nelse:\n    print('\\u274C Oops - your url variable is not the correct length.')\n\nprint('You earned {} of 6 points for defining a url variable'.format(points))"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#download-and-get-started-working-with-ncei-data",
    "href": "notebooks/01a-get-started/get-started.html#download-and-get-started-working-with-ncei-data",
    "title": "Get started with open reproducible science!",
    "section": "Download and get started working with NCEI data",
    "text": "Download and get started working with NCEI data\nThe pandas library you imported can download data from the internet directly into a type of Python object called a DataFrame. In the code cell below, you can see an attempt to do just this. But there are some problems‚Ä¶\n What do you notice about the code below? Answer the following questions in this cell:\n\nWhat do you think the parameters of the pd.read_csv() function are supposed to do? &gt; HINT: Check out the pandas read_csv() documentation for more info. You can also try changing the values and running the cell to see what happens! * my_url: YOUR ANSWER HERE * header: YOUR ANSWER HERE * names: YOUR ANSWER HERE\nAre the data importing correctly? Why or why not?\nYOUR ANSWER HERE\nWhat are two things you could do to make this code more expressive? 1. YOUR ANSWER HERE 2. YOUR ANSWER HERE\n\n You‚Äôre ready to fix some code! Your task is to: 1. Make any changes needed to get this code to run. Here‚Äôs some hints: &gt; HINT: The my_url variable doesn‚Äôt exist - you need to replace it with the variable name you chose. 2. Modify the value of the header parameter so that only numeric data values are included in each column. 3. Clean up the code by using expressive variable names, expressive column names, PEP-8 compliant code, and descriptive comments\nMake sure to call your DataFrame by typing it‚Äôs name as the last line of your code cell Then, you will be able to run the test cell below and find out if your answer is correct.\n=== BEGIN MARK SCHEME ===\n(2 pts) Expressive column names\n\n(2 pts) Expressive variable names\n\n(1 pt) PEP-8\n\n(1 pt) Descriptive comment\n=== END MARK SCHEME ===\n\n#download\ndataframe = pd.read_csv(my_url, header=2, names=['col_1', 'col_2'])\ndataframe\n\n# BEGIN SOLUTION\n# Fix the dataframe variable\ndataframe = pd.read_csv(my_url, header=3, names=['col_1', 'col_2'])\n\n# Read Annual Maximum Temperature Data in to a DataFrame\nsd_tmax_df = pd.read_csv(\n    my_url, \n    header=3,\n    names=['year', 'temperature_f'])\nprint([round(val, 2) for val in sd_tmax_df.mean().values])\nsd_tmax_df\n# END SOLUTION\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nif isinstance(tmax_df_resp, pd.DataFrame):\n    points += 1\n    print('\\u2705 Great work! You called a DataFrame.')\nelse:\n    print('\\u274C Oops - make sure to call your DataFrame for testing.')\n    \nsummary = [round(val, 2) for val in tmax_df_resp.mean().values]\nif summary == [198562.0, 58.89]:\n    points += 4\n    print('\\u2705 Great work! You correctly downloaded data.')\nelse:\n    print('\\u274C Oops - your data are not correct.')\nprint('You earned {} of 5 points for downloading data'.format(points))\n\n\nHINT: Check out the type() function below - you can use it to check that your data is now in DataFrame type object\n\n\n# Check that the data was imported into a pandas DataFrame\ntype(dataframe)"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#cleaning-up-your-dataframe",
    "href": "notebooks/01a-get-started/get-started.html#cleaning-up-your-dataframe",
    "title": "Get started with open reproducible science!",
    "section": "Cleaning up your DataFrame",
    "text": "Cleaning up your DataFrame\nTake a look at your data. Do you want to use it as is, or does it need to be modified? The original author of this code thought it needed some modification, but didn‚Äôt document their work very well.\n Playing with code: your task\n\nReplace dataframe with the name of your dataframe whenever it appears.\nRun the code below.\n\n\n# ncei has wacky years\ndataframe.iloc[:,0] = dataframe.iloc[:,0] // 100\ndataframe\n# BEGIN SOLUTION\nsd_tmax_df.year = sd_tmax_df.year // 100\nprint([round(val, 2) for val in sd_tmax_df.mean().values])\nsd_tmax_df\n# END SOLUTION\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nif isinstance(tmax_df_resp, pd.DataFrame):\n    points += 1\n    print('\\u2705 Great work! You called a DataFrame.')\nelse:\n    print('\\u274C Oops - make sure to call your DataFrame for testing.')\n    \nsummary = [round(val, 2) for val in tmax_df_resp.mean().values]\nif summary == [1985.5, 58.89]:\n    points += 4\n    print('\\u2705 Great work! You correctly cleaned up years.')\nelse:\n    print('\\u274C Oops - your data are not correct.')\nprint('You earned {} of 5 points for cleaning up years'.format(points))\n\n Want an EXTRA CHALLENGE? Modify the code to be more expressive.\nRewrite the code below to select columns by name instead of by index. You might find the pandas User Guide section on slicing and dicing to be useful. However - don‚Äôt worry if you can‚Äôt figure this out yet! We‚Äôre going to talk a lot about how to use pandas DataFrames.\n What just happened? 1. +, -, * and / are known as operators in Python, and are used for arithmetic (add, subtract, multiply, and divide, respectively). What do you think the // operator does?\nYOUR ANSWER HERE\n\niloc is an attribute of DataFrames, meaning that it is available for all DataFrames by attaching .iloc to the end its name. What do you think the iloc is or does?\n\nYOUR ANSWER HERE\n\nHINT: It‚Äôs ok if you can‚Äôt figure out these questions yet. You can also list an experiment you tried. For example, you could run 4 // 2 and 4 // 3 in a new code cell and record the answers to help you figure out what // does. Or, you could change the 0 in .iloc[:,0] to 1 to see what happens. Play around with the code! It doesn‚Äôt cost you anything to try things when you‚Äôre coding."
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#uh-oh-we-have-a-variable-problem",
    "href": "notebooks/01a-get-started/get-started.html#uh-oh-we-have-a-variable-problem",
    "title": "Get started with open reproducible science!",
    "section": "Uh-oh, we have a variable problem",
    "text": "Uh-oh, we have a variable problem\n Try running the cell above a second time. And a third time. What do you notice?\nYOUR ANSWER HERE\nYou don‚Äôt have to do anything about this now - you can go Run all to reset. In the future, there are two approaches we recommend to address this sort of problem: 1. Do not modify a DataFrame after it has been created - perform any changes you need in the same cell where you create the DataFrame using pd.read_csv(). 2. Save a copy of the DataFrame using the .copy() method of DataFrames and modify the copy (in the same cell)"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#data-conversion-to-celcius",
    "href": "notebooks/01a-get-started/get-started.html#data-conversion-to-celcius",
    "title": "Get started with open reproducible science!",
    "section": "Data Conversion to Celcius",
    "text": "Data Conversion to Celcius\nThe cell below converts the data to Celcius, using Python mathematical operators. Again, it‚Äôs not well documented and doesn‚Äôt follow PEP-8 guidelines. This has caused the author to miss an important error!\n Your task: 1. Replace the variable name dataframe with the name of your DataFrame. 2. Fix the error\n What is the mistake in the equation below? You might want to try writing out the formula for converting Fahrenheit to Celcius.\nYOUR ANSWER HERE\n\n#convert to celcius\ndataframe.iloc[:,1] = dataframe.iloc[:,1] - 32 * 5 / 9\ndataframe\n# BEGIN SOLUTION\nsd_tmax_df['temperature_c'] = (sd_tmax_df['temperature_f'] - 32) * 5/9\nprint([round(val, 2) for val in sd_tmax_df.mean().values])\nsd_tmax_df\n# END SOLUTION\n\n\n# DO NOT MODIFY THIS TEST CELL\ntmax_df_resp = _\npoints = 0\n\nif isinstance(tmax_df_resp, pd.DataFrame):\n    points += 1\n    print('\\u2705 Great work! You called a DataFrame.')\nelse:\n    print('\\u274C Oops - make sure to call your DataFrame for testing.')\n    \nsummary = [round(val, 2) for val in tmax_df_resp.mean().values]\nif summary == [1985.5, 59.04, 15.02]:\n    points += 4\n    print('\\u2705 Great work! You correctly converted to Celcius.')\nelse:\n    print('\\u274C Oops - your data are not correct.')\nprint('You earned {} of 5 points for converting to Celcius'.format(points))\n\n Want an EXTRA CHALLENGE? 1. As you did above, rewrite the code to be more expressive 2. Using the code below as a framework, write and apply a function that converts to Celcius. &gt; Functions let you reuse code you have already written\n\nYou should also rewrite this function name to be more expressive.\ndef convert(temperature):\n    \"\"\"Convert temperature to Celcius\"\"\"\n    return temperature # Put your equation in here\n\ndataframe['temp_c'] = dataframe['temp_f'].apply(convert)"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#plot-the-maximum-annual-temperature-in-rapid-city-sd-usa",
    "href": "notebooks/01a-get-started/get-started.html#plot-the-maximum-annual-temperature-in-rapid-city-sd-usa",
    "title": "Get started with open reproducible science!",
    "section": "Plot the maximum annual temperature in Rapid City, SD, USA",
    "text": "Plot the maximum annual temperature in Rapid City, SD, USA\nPlotting in Python is easy, but not quite this easy! You‚Äôll always need to add some instructions on labels and how you want your plot to look.\n\nChange dataframe to your DataFrame name.\nChange 'col_1' and 'col_2' to your column names\nUse the title, ylabel, and xlabel parameters to add key text to your plot.\n\n\nHINT: labels have to be a type in Python called a string. You can make a string by putting quotes around your label, just like the column names in the sample code.\n\n\ndataframe.plot(x='col_1', y='col_2')\n\n# BEGIN SOLUTION\nsd_tmax_df.plot(\n    y='temperature_c',\n    x='year',\n    legend=False,\n    title='Maximum Annual Temperature in Rapid City, SD, USA',\n    ylabel='Temperature ($^\\circ$F)',\n    xlabel='Year',\n    figsize=(8, 6))\n# END SOLUTION\n\nTHIS ISN‚ÄôT THE END! Don‚Äôt forget to complete the next task where you will describe your plot\n\n\nImage source: https://www.nps.gov/pais/learn/nature/hatchlingreleases.htm\n\n Want an EXTRA CHALLENGE?\nThere are many other things you can do to customize your plot. Take a look at the pandas plotting galleries and the documentation of plot to see if there‚Äôs other changes you want to make to your plot. Some possibilities include: * Remove the legend since there‚Äôs only one data series * Increase the figure size * Increase the font size * Change the colors * Use a bar graph instead (usually we use lines for time series, but since this is annual it could go either way) * Add a trend line"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#describe-your-plot-in-the-markdown-cell-below",
    "href": "notebooks/01a-get-started/get-started.html#describe-your-plot-in-the-markdown-cell-below",
    "title": "Get started with open reproducible science!",
    "section": "Describe your plot in the Markdown cell below",
    "text": "Describe your plot in the Markdown cell below\nWe like to use an approach called ‚ÄúAssertion-Evidence‚Äù for presenting scientific results. There‚Äôs a lot of video tutorials and example talks available on the Assertion-Evidence web page. The main thing you need to do now is to practice writing a message or headline rather than descriptions or topic sentences for the plot you just made (what they refer to as ‚Äúvisual evidence‚Äù).\nFor example, it would be tempting to write something like ‚ÄúA plot of maximum annual temperature in Rapid City, South Dakota over time (1947-2023)‚Äù. However, this doesn‚Äôt give the reader anything to look at, or explain why we made this particular plot (we know, you made this one because we told you to)\nSome alternatives that are more of a starting point for a presentation or conversation are: * Rapid City, SD, USA experienced extreme heat in 2013 * Extreme temperatures in Rapid City, SD appear to be on the rise over the past 70 years * Maximum annual temperatures in Rapid City, SD are becoming more variable over the previous 70 years\nWe could back up some of these claims with further analysis included later on, but we want to make sure that our audience has some guidance on what to look for in the plot.\n=== BEGIN MARK SCHEME ===\n(2 pts) Headline\n\n(3 pts) Description\n=== END MARK SCHEME ==="
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#your-rapid-city-plot-headline-here",
    "href": "notebooks/01a-get-started/get-started.html#your-rapid-city-plot-headline-here",
    "title": "Get started with open reproducible science!",
    "section": "YOUR RAPID CITY PLOT HEADLINE HERE",
    "text": "YOUR RAPID CITY PLOT HEADLINE HERE\nDescribe your plot in this cell in 2-3 sentences\nTHIS ISN‚ÄôT THE END EITHER! Don‚Äôt forget to reproduce your analysis in a new location!\n\n\nImage source: https://www.independent.co.uk/climate-change/news/by-the-left-quick-march-the-emperor-penguins-migration-1212420.html"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#your-turn-pick-a-new-location-andor-measurement-to-plot",
    "href": "notebooks/01a-get-started/get-started.html#your-turn-pick-a-new-location-andor-measurement-to-plot",
    "title": "Get started with open reproducible science!",
    "section": "Your turn: pick a new location and/or measurement to plot",
    "text": "Your turn: pick a new location and/or measurement to plot\nBelow, recreate the workflow you just did in a place that interests you OR with a different measurement. See the instructions above fore how to get your URL. You will need to make your own new Markdown and Code cells below this one."
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#congratulations-you-finished-this-coding-challenge-now-make-sure-that-your-code-is-reproducible",
    "href": "notebooks/01a-get-started/get-started.html#congratulations-you-finished-this-coding-challenge-now-make-sure-that-your-code-is-reproducible",
    "title": "Get started with open reproducible science!",
    "section": "Congratulations, you finished this coding challenge ‚Äì now make sure that your code is reproducible",
    "text": "Congratulations, you finished this coding challenge ‚Äì now make sure that your code is reproducible\n\nIf you didn‚Äôt already, go back to the code you modified about and write more descriptive comments so the next person to use this code knows what it does.\nMake sure to Restart and Run all up at the top of your notebook. This will clear all your variables and make sure that your code runs in the correct order. It will also export your work in Markdown format, which you can put on your website.\n\n\n\nImage source: https://dfwurbanwildlife.com/2018/03/25/chris-jacksons-dfw-urban-wildlife/snow-geese-galore/\n\n\n!jupyter nbconvert --to markdown *.ipynb --TagRemovePreprocessor.remove_cell_tags='{\"remove_cell\"}'"
  },
  {
    "objectID": "notebooks/01a-get-started/get-started.html#bibliography",
    "href": "notebooks/01a-get-started/get-started.html#bibliography",
    "title": "Get started with open reproducible science!",
    "section": "Bibliography",
    "text": "Bibliography\nEarth Science Data Systems, N. (2021, October 5). Open Source Science for the Earth System Observatory Mission Data Processing Study Workshops | Earthdata [Tutorial]. Earth Science Data Systems, NASA. https://www.earthdata.nasa.gov/technology/open-science/oss-for-eso-workshops\nU.S. Geological Survey. (n.d.). Landsat 8 [Remote-sensing image]. National Aeronautics and Space Administration, U.S. Government, U.S. Geological Survey. Retrieved April 4, 2024, from http://eros.usgs.gov"
  },
  {
    "objectID": "notebooks/02-flood/flood.html",
    "href": "notebooks/02-flood/flood.html",
    "title": "In March of 2019 there were floods in South Dakota, USA",
    "section": "",
    "text": "In March 2019, large parts of South Dakota were flooded for weeks. What happened to cause this flooding? What impacts did the flooding have? Before we look at data about the flooding, we need to check out what other sources are saying about it.\nüìñ Here are some resources from different sources to get you started: * The National Weather Service * South Dakota Public Radio * The Intercept\nüí¨ If you or someone you know have experience with this site, or were there during the floods, we also invite you to write about that."
  },
  {
    "objectID": "notebooks/02-flood/flood.html#the-cheyenne-river-near-wasta-sd-was-one-of-the-locations-affected-by-the-flooding",
    "href": "notebooks/02-flood/flood.html#the-cheyenne-river-near-wasta-sd-was-one-of-the-locations-affected-by-the-flooding",
    "title": "In March of 2019 there were floods in South Dakota, USA",
    "section": "The Cheyenne River near Wasta, SD was one of the locations affected by the flooding",
    "text": "The Cheyenne River near Wasta, SD was one of the locations affected by the flooding\nTo start, you‚Äôll be focusing on the Cheyenne River, which flows into Lake Oahu. Then, you‚Äôll pick your own site that was affected by a flood.\n\nSite Description\n‚úé In the cell below, describe the Cheyenne River area in a few sentences. You can include: * Information about the climatology of the area, or typical precipitation and temperature at different months of the year * The runoff ratio (average annual runoff divided by average annual precipitation) * Which wildlife and ecosystems exist in the area * What communities and infrastructure are in the area\n\n\nInteractive Site Map\n\nGet set up to use Python\nUse the cell below to add necessary package imports to this notebook. It‚Äôs best to import everything in your very first code cell because it helps folks who are reading your code to figure out where everything comes from (mostly right now this is you in the future). It‚Äôs very frustrating to try to figure out what packages need to be installed to get some code to run.\nüìñ Our friend the PEP-8 style guide has some things to say about imports. In particular - standard library packages should be listed at the top. These are packages that you don‚Äôt need to install because they come with Python. You can check if a package is part of the standard library by searching the Python Standard Library documentation page.\nüíª Your task: * Uncomment all the import lines below. HINT: Use the CMD-/ shortcut to uncomment many lines at once. * Add the library for working with DataFrames in Python to the imports * Separate the standard library package(s) at the top * Run and test your import cell to make sure everything will work\n\n# import folium\n# from io import BytesIO\n# import matplotlib.pyplot as plt\n# import matplotlib.dates as dates\n# import requests\n# import subprocess\n\n# BEGIN SOLUTION\nimport subprocess\nfrom io import BytesIO\n\nimport folium\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as dates\nimport pandas as pd\nimport requests\n# END SOLUTION\n\n\n# Test package imports - DO NOT MODIFY THIS CELL!\nimport_answer_points = 3\n\n# Check that pandas has been imported properly\ntry:\n    na_val = pd.NA\n    print(\"\\u2705 Score! Pandas has been imported as a pd!\")\n    import_answer_points += 2\nexcept NameError:\n    print(\n        \"\\u274C Pandas has not been imported as a pd, please make \"\n        \"sure to import it properly.\"\n    )\n\n# Subtract one point for any PEP-8 errors\ntmp_path = \"tmp.py\"\nwith open(tmp_path, \"w\") as tmp_file:\n    tmp_file.write(In[-2])\nignore_flake8 = 'W292,F401,E302'\nflake8_out = subprocess.run(\n    ['flake8', \n     '--ignore', ignore_flake8, \n     '--import-order-style', 'edited',\n     '--count', \n     tmp_path],\n    stdout=subprocess.PIPE,\n).stdout.decode(\"ascii\")\nprint(flake8_out)\nimport_answer_points -= int(flake8_out.splitlines()[-1])\n\nprint(\n    \"\\n \\u27A1 You received {} out of 5 points.\".format(import_answer_points)\n)\n\nimport_answer_points\n\n\n\n\nSite Map: The Cheyenne River near Wasta\nThe code below will create an interactive map of the area using the folium library. But something is wrong - no one defined the latitude and longitude as variables.\nüíª Your task: * Find the location of the Cheyenne River near Wasta USGS stream gauge using the National Water Information System. This is not the easiest thing to find if you aren‚Äôt used to NWIS, so you can use the following instructions to get started: * Go to the National Water Information System Mapper * Type in Wasta in the Find a Place box * Click on the Cheyenne River near Wasta site. It should open a new window. * Click on Site page at the top * Scroll to the bottom and open the Location metadata section. * Define latitude and longitude variables to match the variable names used in the code. * Change the current label, ‚ÄúThingy‚Äù to be descriptive of the site. * Run and test your cell to make sure everything works.\nüå∂ EXTRA CHALLENGE: Customize your folium plot using the folium documentation. For example, you could: * Change the base map images * Change the initial zoom\n\n# BEGIN SOLUTION\nsg_lat = 44.08109849 \nsg_lon = -102.4012746\n# END SOLUTION\n\n# Initialize map and tweak settings\nm = folium.Map(\n    # Location to display\n    location=(sg_lat, sg_lon),\n    # Turns off annoying zooming while trying to scroll to the next cell\n    scrollWheelZoom=False)\n\n# Put a marker at the stream gauge location\nfolium.Marker([sg_lat, sg_lon], popup=\"Thingy\").add_to(m)\n\n# Display the map\nm"
  },
  {
    "objectID": "notebooks/02-flood/flood.html#one-way-to-express-how-big-a-flood-is-by-estimating-how-often-larger-floods-occur.",
    "href": "notebooks/02-flood/flood.html#one-way-to-express-how-big-a-flood-is-by-estimating-how-often-larger-floods-occur.",
    "title": "In March of 2019 there were floods in South Dakota, USA",
    "section": "One way to express how big a flood is by estimating how often larger floods occur.",
    "text": "One way to express how big a flood is by estimating how often larger floods occur.\nFor example, you might have heard news media talking about a ‚Äú100-year flood‚Äù.\nIn this notebook, you will write Python code to download and work with a time series of streamflow data during the flooding on the Cheyenne River.\n\nA time series of data is taken at the same location but collected regularly or semi-regularly over time.\n\nYou will then consider how the values compared to previous years before the flood event by computing the flood‚Äôs return period.\n\nA return period is an estimate of how often you might expect to see a flood of at least a particular size. This does NOT mean an extreme flood ‚Äúhas‚Äù to occur within the return period, or that it couldn‚Äôt occur more than once.\n\nüìñ Here are some resources from your text book you can review to learn more: * Introduction to time-series data * Flood return period and probability\n‚úé In the cell below, explain what data you will need to complete this analysis, including: 1. What type or types of data do you need? 2. How many years of data do you think you need to compute the return period of an extreme event like the 2019 Cheyenne River floods?\nYOUR ANSWER HERE\n\nUS streamflow data are available from the National Water Information Service (NWIS)\nüíª Practice downloading the data you need using the NWIS website. You will not use your downloaded data in the analysis, but you must follow these steps to get the correct urls. In the cell below, use the following instructions to get urls for downloading the USGS data:\n\nGo back to the Cheyenne River near Wasta station page.\nThis time, click Data instead of Site Page\nSelect Daily Data from the list of datasets.\nSelect the entire available date range, and set your results to be as Tab-separated, and press Go.\nCopy the url that populates in your browser window and paste it below. You don‚Äôt need to save the data - we will do that using Python.\n\n=== BEGIN MARK SCHEME ===\nUSGS url: https://waterdata.usgs.gov/nwis/dv?cb_00060=on&format=rdb&site_no=06423500&legacy=&referred_module=sw&period=&begin_date=1914-10-01&end_date=2023-04-29\n=== END MARK SCHEME ===\n‚úé USGS streamflow URL: url here\n\nExploring the NWIS API\nOne way to access data is through an Application Programming Interface, or API. The URL you‚Äôve just found is an example of a simple, public API. All the parameters of your data search are visible in the URL. For example, to get data starting in 1950, we could change begin_date=1914-10-01 to begin_date=1950-01-01)\n‚úé In the cell below - what parameter would you change in the USGS url if you wanted to switch locations?\n=== BEGIN MARK SCHEME ===\nsite_no\n=== END MARK SCHEME ====\n\n\nData description and citation\n‚úé In the cell below, describe your data. Include the following information: 1. A 1-2 sentence description of the data 2. Data citation 3. What are the units? 4. What is the time interval for each data point? 5. Is there a ‚Äúno data‚Äù value, or a value used to indicate when the sensor was broken or didn‚Äôt detect anything? (These are also known as NA, N/A, NaN, nan, or nodata values)\nüìñ The NWIS data format page might be helpful.\n\n\nDownload the data\nIn the cell below complete the following task:\n\nReplace the empty string '' in the code below with the USGS NWIS URL you found, saving it in the nwis_url variable.\nDownload the data using the provided code.\nSave the result (or HTTP Response) to a descriptive variable, and call the variable at the end of the cell.\n\n\nnwis_url = ''\n# BEGIN SOLUTION\nnwis_url = (\n    'https://waterdata.usgs.gov/nwis/dv'\n    '?cb_00060=on'\n    '&format=rdb'\n    '&site_no=06423500'\n    '&period=&'\n    'begin_date=1914-10-01'\n    '&end_date=2023-04-29'\n)\nresponse = requests.get(nwis_url)\n# END SOLUTION\n\n# Download data using a GET HTTP Request\nrequests.get(nwis_url)\n\n\nans_req = _\nreq_pts = 0\n\nif ans_req.ok:\n    print('\\u2705 Great work! Your download succeeded')\n    req_pts +=2\nelse:\n    print('\\u274C Hmm, looks like your url is not correct')\n\nprint('\\u27A1 You earned {} of 2 points for downloading data'.format(req_pts))\n\n\n\nYou will need to take a look at the raw downloaded data to figure out what import parameters to use with the pandas read_csv() function\nüíª In the cell below, replace response with the name of the response variable that you defined above.\nThe code below prints the first 10 lines of your download and numbers them. Does this look like streamflow data to you?\n\nfor i, line in enumerate(response.content.splitlines()[:10]):\n    print(i, line)\n\nIn the NWIS documentation, they say that you can ignore lines that start with a hash sign (#) because they are commented. When we use pandas to import the data, we‚Äôll be able to tell it what character indicates a comment, but we‚Äôre not there yet. The code below again prints the first 35 lines of the response content, this time skipping all commented lines.\nüíª In the cell below, replace response with the name of the response variable that you defined above. Then run the code.\n\n# Take a look at the data. What got downloaded?\nfor i, line in enumerate(response.content.splitlines()[:35]):\n    if not line.startswith(b'#'):\n        print(i, line)\n\n‚úé What do you notice about the data now? In the following cell, write down your thoughts on: * What separator or delimiter does the data use to separate columns? * What should the data types of each column be? * Which column contains the streamflow data? * Do you need to skip any rows that don‚Äôt contain data? * Which column do you think makes sense as the index (unique identifier) for each row? * Is there anything else strange?\nThe answers to the questions above will help you figure out what parameters to use with the pd.read_csv() function.\n\n\nNow we‚Äôre ready to import the data with pandas.\nNotice that when you print your downloaded data, each line has a b in front of it. The b stands for ‚Äúbytes‚Äù. In order for pandas to be able to read the data, we need to decode it so each line is a regular string. In the cell below, we do this using the io.BytesIO function, which tricks pandas into thinking it is reading a binary file.\nüíª Your task: * Replace response with the name of your HTTP Response variable * Uncomment the code below, one line at a time. * Using the observations you made above, add the necessary values to get pandas to correctly import the data. * Make sure to include units in your column names where applicable! What units are these streamflow measurements?\n\npd.read_csv(\n    BytesIO(response.content),\n    comment='#',\n    #delimiter='', \n    #skiprows=[],\n    #names=[],\n    #index_col='',\n    #parse_dates=True,\n)\n\n# BEGIN SOLUTION #\ndataframe = pd.read_csv(\n    BytesIO(response.content), \n    sep='\\t', \n    comment='#',\n    skiprows=[29, 30],\n    names=['agency', 'site', 'datetime', 'streamflow_cfs', 'code'],\n    index_col='datetime',\n    parse_dates=True)\ndataframe\n# END SOLUTION\n\n\nans_df = _\ndf_points = 0\n\nif len(ans_df) &gt;= 39658:\n    print(\"\\u2705 Looks like your DataFrame has enough rows!\")\n    df_points += 2\nelse:\n    print(\"\\u274C Oops, your DataFrame doesnt have enough rows\")\n\nif len(ans_df.columns) == 4:\n    print(\"\\u2705 Looks like your DataFrame has enough columns!\")\n    df_points += 2\nelif len(ans_df.columns) == 5:\n    print(\"\\u274C Hmm, looks like you didn't set an index column\")\nelse:\n    print(\"\\u274C Oops, your DataFrame doesn't have the right number of \"\n          \"columns\")\n    \nprint(\"\\u27A1 You earned {} of 4 points\".format(df_points))\n\nLet‚Äôs check your data. A useful method for looking at the datatypes in your pd.DataFrame is the pd.DataFrame.info() method.\n\nIn Python, you will see both methods and functions. This is an important and tricky distinction we‚Äôll be talking about a lot. For right now ‚Äì functions have all of their arguments/parameters inside the parentheses, as in pd.read_csv(args). For methods, the first argument is always some kind of Python object like a pd.DataFrame. Take a look at the next cell for an example of using the pd.DataFrame.info() method.\n\nüíª Replace dataframe with the name of your DataFrame variable\n\ndataframe.info()\n\nOops, we have one more problem! Take a look at the data types of your DataFrame columns‚Ä¶\n‚úé In the cell below, write down what data type you would expect the streamflow column to be. The main options are: Integer, Float, Datetime, or Object.\nüìñ Check out this example showing the most common data types for pandas columns\n\nA float is a non-integer number. You can identify them because they have decimal points in Python, unlike integers. We do not call them decimals for a reason - a decimal.Decimal is different, and more precise than, a float in Python. If you are ever working with really, really small numbers, you may need to use decimals, but for most applications floats are fine.\n\npandas was able to apply the correct data type to some columns, but not to the streamflow column. One reason this happens is because there are some values in the DataFrame that cannot be read in or parsed as the same data type as everything else. Often, these are no data values. Unfortunately, the documentation does not list any no data values.\nThe code below runs through the values in the streamflow column one by one. It tries to convert each value to a float, but if it fails it prints the result and then stops.\n\nQ is a common variable name for streamflow in hydrology\n\nüíª Replace dataframe below with your DataFrame name, and streamflow_cfs with your streamflow column name.\n\nfor q in dataframe.streamflow_cfs:\n    try: \n        float(q)\n    except:\n        print(q)\n        break\n\nLooks like some of the streamflow data is a string instead of a number. This lets us know that no data could be taken that day because the Cheyenne River was frozen! We can let Python know that there isn‚Äôt any data there using the na_values='...' parameter. Substitute the value you found for the ...\nüíª Re-import your data below, this time indicating an NA value. Call your new DataFrame at the end for testing.\n\n# BEGIN SOLUTION #\ndataframe = pd.read_csv(\n    BytesIO(response.content), \n    sep='\\t', \n    comment='#',\n    skiprows=[29, 30],\n    names=['agency', 'site', 'datetime', 'streamflow_cfs', 'code'],\n    index_col='datetime',\n    parse_dates=True,\n    na_values='Ice')\nprint(round(dataframe.iloc[:,2].mean(), 0))\nprint(dataframe.iloc[:,2].dtype)\ndataframe\n# END SOLUTION\n\n\nans_q = _\nq_points = 0\n\nif isinstance(ans_q, pd.DataFrame):\n    print(\"\\u2705 Great, you created a pandas dataframe above\")\n    q_points += 1\nelse:\n    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n\nif type(ans_q.index) == pd.DatetimeIndex:\n    print(\"\\u2705 Your DataFrame has the date as the index, \"\n          \"good job!\")\n    q_points += 1\nelse:\n    print(\"\\u274C Your DataFrame does not have the date \"\n          \"as the index.\")\n    \nimport numpy as np\nif ans_q.iloc[:,2].dtype == np.float64:\n    print(\"\\u2705 Your streamflow column is floats!\")\n    q_points += 2\nelse:\n    print(\"\\u274C Your streamflow column still isn't floats.\")\n\nif round(ans_q.iloc[:,2].mean(), 0)==385:\n    print(\"\\u2705 Your streamflow DataFrame has the expected values \"\n          \"in it, good job!\")\n    q_points += 2\nelse:\n    print(\"\\u274C Your streamflow DataFrame does not have the \"\n          \"expected values in it.\")\n\nprint(\"\\u27A1 You received {} out of 6 points for opening the \"\n      \"streamflow data.\".format(\n    q_points))\nq_points\n\n\n\n\nCan we see the flood in the streamflow data?\nIn the cell below, subset the stream discharge data to the same timeframe that you are interested in: February - April, 2019. Save the result to a variable and call it at the end of the cell for testing.\nYou can find some examples of subsetting time series data in the textbook.\n\n# BEGIN SOLUTION\ndataframe_subset = dataframe['2019-02':'2019-04']\nprint(round(dataframe_subset.iloc[:,2].mean(), 0))\ndataframe_subset\n# END SOLUTION\n\n\nans_subset = _\nsubset_points = 0\n\n# Answer should be a DataFrame\nif isinstance(ans_subset, pd.DataFrame):\n    print(\"\\u2705 Great, you created a pandas dataframe above\")\n    subset_points += 1\nelse:\n    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n\n# Answer should have a Datetime index\nif type(ans_subset.index) == pd.DatetimeIndex:\n    print(\"\\u2705 Your DataFrame has the date as the index, \"\n          \"good job!\")\n    subset_points += 1\nelse:\n    print(\"\\u274C Your DataFrame does not have the date \"\n          \"as the index.\")\n\n# Answer should include 89 days of data\nif len(ans_subset)==89:\n    print(\"\\u2705 Your DataFrame has the right number of days\")\n    subset_points += 2\nelif len(ans_subset) &gt; 89:\n    print(\"\\u274C Your subset has too many days.\")\nelse:\n    print(\"\\u274C Your subset has too few days.\")\n\n# The mean of the streamflow column should be 1951\nif round(ans_subset.iloc[:,2].mean(), 0)==1951:\n    print(\"\\u2705 Your streamflow DataFrame has the expected values \"\n          \"in it, good job!\")\n    subset_points += 1\nelse:\n    print(\"\\u274C Your streamflow DataFrame does not have the \"\n          \"expected values in it.\")\n\nprint(\"\\u27A1 You received {} out of 5 points for subsetting the \"\n      \"streamflow data.\".format(\n    subset_points))\nsubset_points\n\nüíª Now, in the cell below, plot your subsetted data. Don‚Äôt forget to label your plot!\n=== BEGIN MARK SCHEME ===\n\n(2 pts) Subsetted data plotted with dates on the x-axis\n(3 pts) Appropriate axis labels\n(2 pt) Appropriate title or caption\n\n=== END MARK SCHEME ===\n\n# BEGIN SOLUTION\n(dataframe_subset\n .streamflow_cfs\n .plot(\n     xlabel='', \n     ylabel='Streamflow (cfs)',\n     title='Streamflow on the Cheyenne River during a flood'))\nplt.show()\n# END SOLUTION\n\nYou should be able to see the flood in your data going up above 12000 cfs at its peak. But how unusual is that really?\nLet‚Äôs start by plotting ALL the data. Then we‚Äôll use a return period statistic to quantify how unusual it was.\nüíª In the cell below, plot the entire time series of streamflow data, without any parameters.\n\n# BEGIN SOLUTION\n\ndataframe.streamflow_cfs.plot()\n\n# END SOLUTION\n\nThis plot looks a little fuzzy because it is trying to fit too many data points in a small area. One way to improve this is by resampling the data to annual maxima. That way we still get the same peak streamflows, but the computer will be able to plot all the values without overlapping.\n\nResampling means changing the time interval between time series observations - in this case from daily to annual.\n\nüìñ Read about different ways to resample time series data in your textbook\nüìñ You can use a list of offset aliases to look up how to specify the final dates. This list is pretty hard to find - you might want to bookmark it.\nüíª In the cell below, select the streamflow column, and then resample it to get an annual maximum.\n\nWatch out for this gotcha - the test below is looking for a pandas DataFrame, but when we select a single column we get a pandas Series (a DataFrame is a collection of Series.) To get a DataFrame with a single column, use the syntax below with two square brackets:\n\ndataframe[['column_name']]\n\n# BEGIN SOLUTION\n\ndataframe_annual = dataframe[['streamflow_cfs']].resample('AS').max()\nprint(round(int(dataframe_annual.mean()), 0))\ndataframe_annual\n\n# END SOLUTION\n\n\nans_resample = _\nresample_points = 0\n\n# Answer should be a DataFrame\nif isinstance(ans_resample, pd.DataFrame):\n    print(\"\\u2705 Great, you created a pandas DataFrame above\")\n    resample_points += 1\nelse:\n    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n\n# Answer should have a Datetime index\nif type(ans_resample.index) == pd.DatetimeIndex:\n    print(\"\\u2705 Your DataFrame has the date as the index, \"\n          \"good job!\")\n    resample_points += 1\nelse:\n    print(\"\\u274C Your DataFrame does not have the date \"\n          \"as the index.\")\n\n# Answer should include 89 days of data\nif len(ans_resample)&gt;=110:\n    print(\"\\u2705 Your DataFrame has the right number of years\")\n    resample_points += 2\nelse:\n    print(\"\\u274C Oops - did you resample your DataFrame to annual?\")\n\n# The mean of the streamflow Series should be 7888\nif round(int(ans_resample.mean()), 0)==7888:\n    print(\"\\u2705 Your annual max streamflow DataFrame has the expected \"\n          \"values in it, good job!\")\n    resample_points += 1\nelse:\n    print(\"\\u274C Your annual max streamflow DataFrame does not have the \"\n          \"expected values in it.\")\n\nprint(\"\\u27A1 You received {} out of 5 points for subsetting the \"\n      \"streamflow data.\".format(\n    resample_points))\nresample_points\n\nüíª Plot your resampled data.\n\n# BEGIN SOLUTION\n\ndataframe_annual.plot(\n    figsize=(14, 4),\n    xlabel='Year',\n    ylabel='Daily Streamflow (cfs)',\n    title='Annual Maximum Daily Streamflow Values on the Cheyenne River')\nplt.show()\n# END SOLUTION\n\nIn the cell below, write a headline and 2-3 sentence description of your plot. What do you estimate the return period was for the flood in 2019?\nüå∂ In the cell below, calculate the exceedence probability and return period for each year of the annual data, and add them as columns to your DataFrame.\n\nHINT: pandas columns have a rank method, which you can use. BUT ‚Äì you will need to use the ascending=False parameter, since higher rank should be lower exceedence probability\n\n\n# BEGIN SOLUTION\n\ndataframe_annual['exceed_prob'] = (\n    dataframe_annual.rank(ascending=False).streamflow_cfs / len(dataframe_annual))\ndataframe_annual['return_period'] = 1 / dataframe_annual.exceed_prob\n\nprint(round(dataframe_annual.mean().product(), 0))\ndataframe_annual\n\n# END SOLUTION\n\n\nans_return = _\nreturn_points = 0\n\n# Answer should be a DataFrame\nif isinstance(ans_return, pd.DataFrame):\n    print(\"\\u2705 Great, you created a pandas dataframe above\")\n    return_points += 1\nelse:\n    print(\"\\u274C Oops - the cell above should have a DataFrame output.\")\n\n# Answer should have a Datetime index\nif type(ans_return.index) == pd.DatetimeIndex:\n    print(\"\\u2705 Your DataFrame has the date as the index, \"\n          \"good job!\")\n    return_points += 1\nelse:\n    print(\"\\u274C Your DataFrame does not have the date \"\n          \"as the index.\")\n\n# Answer should include 110 years of data\nif len(ans_return)==110:\n    print(\"\\u2705 Your DataFrame has the right number of days\")\n    return_points += 2\nelif len(ans_return) &gt; 110:\n    print(\"\\u274C Your DataFrame has too many years.\")\nelse:\n    print(\"\\u274C Your DataFrame has too few years.\")\n\n# The value \"hash\" should be 20549.0\nif round(ans_return.mean().product(), 0)==20549.0:\n    print(\"\\u2705 Your streamflow DataFrame has the expected values \"\n          \"in it, good job!\")\n    return_points += 1\nelse:\n    print(\"\\u274C Your streamflow DataFrame does not have the \"\n          \"expected values in it.\")\n\nprint(\"\\u27A1 You received {} out of 5 extra credit points for calculating the \"\n      \"return period.\".format(return_points))\nreturn_points"
  },
  {
    "objectID": "notebooks/02-flood/flood.html#pep-8-and-does-the-notebook-run",
    "href": "notebooks/02-flood/flood.html#pep-8-and-does-the-notebook-run",
    "title": "In March of 2019 there were floods in South Dakota, USA",
    "section": "Pep 8, and Does the Notebook Run?",
    "text": "Pep 8, and Does the Notebook Run?\nIn this cell, we will give you points for the following\n\nPEP 8 is followed throughout the notebook (3 points)\nThe notebook runs from top to bottom without any editing (it is reproducible) (3 points)"
  }
]