{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mapping Tasiyagnunpa (Western Meadowlark) migration\n",
        "\n",
        "Introduction to vector data operations\n",
        "\n",
        "Tasiyagnunpa (Western Meadowlark, or sturnella neglecta) migrates each\n",
        "year to next on the Great Plains in the United States. Using\n",
        "crowd-sourced observations of these birds, we can see that migration\n",
        "happening throughout the year.\n",
        "\n",
        "> Read more about the Lakota connection to Tasiyagnunpa from [Native Sun\n",
        "> News\n",
        "> Today](https://www.nativesunnews.today/articles/meadowlarks-still-speak-lakota-humans-dont-anymore/)\n",
        "\n",
        "## Import Python libraries"
      ],
      "id": "c634a34c-b449-45f1-b732-54bd4bc3188f"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import calendar\n",
        "import os\n",
        "import pathlib\n",
        "import requests\n",
        "import ssl\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "import geopandas as gpd\n",
        "import geoviews as gv\n",
        "import holoviews as hv\n",
        "import hvplot.pandas\n",
        "import pandas as pd\n",
        "import tqdm"
      ],
      "id": "e2d72853"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a folder for your data"
      ],
      "id": "b575ddd1-f467-499d-b881-6ed7ceca6085"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data directory\n",
        "data_dir = os.path.join(\n",
        "    pathlib.Path.home(),\n",
        "    'earth-analytics',\n",
        "    'data',\n",
        "    'species-distribution',\n",
        ")\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "gbif_path_tmpl = os.path.join(data_dir, 'meadowlark_observations_{month:02d}.csv')"
      ],
      "id": "7a9a31e1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define your study area\n",
        "\n",
        "Track observations of Taciyagnunpa across the different **ecoregions**\n",
        "of North America! You should be able to see changes in the number of\n",
        "observations in each ecoregion throughout the year.\n",
        "\n",
        "### Download and save ecoregion boundaries\n",
        "\n",
        "> **<i class=\"fa fa-solid fa-keyboard fa-large\" aria-label=\"keyboard\"></i>\n",
        "> Your Task**\n",
        ">\n",
        "> 1.  Find the URL for for the level III ecoregion boundaries. You can\n",
        ">     [get ecoregion boundaries from the Environmental Protection Agency\n",
        ">     (EPA).](https://www.epa.gov/eco-research/ecoregions-north-america).\n",
        "> 2.  Replace `your/url/here` with the URL you found, making sure to\n",
        ">     format it so it is easily readable.\n",
        "> 3.  Change all the variable names to **descriptive** variable names\n",
        "> 4.  Run the cell to download and save the data."
      ],
      "id": "7d1c4617-a18e-4c17-aebb-36be8f7435b9"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up the ecoregions level III boundary URL\n",
        "a_url = (\"your/url/here\")\n",
        "# Set up a path to save the dataon your machine\n",
        "a_path = os.path.join(data_dir, 'filename.zip')\n",
        "\n",
        "# Don't download twice\n",
        "if not os.path.exists(a_path):\n",
        "    # Download, and don't check the certificate for the EPA\n",
        "    a_response = requests.get(a_url, verify=False)\n",
        "    # Save the binary data to a file\n",
        "    with open(a_path, 'wb') as a_file:\n",
        "        a_file.write(a_response.content)"
      ],
      "id": "d650afc1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the ecoregions into Python\n",
        "\n",
        "> **<i class=\"fa fa-solid fa-keyboard fa-large\" aria-label=\"keyboard\"></i>\n",
        "> Your task**\n",
        ">\n",
        "> Download and save ecoregion boundaries from the EPA:\n",
        ">\n",
        "> 1.  Replace `a_path` with the path your created for your ecoregions\n",
        ">     file.\n",
        "> 2.  (optional) Consider renaming and selecting columns to make your\n",
        ">     `GeoDataFrame` easier to work with.\n",
        "> 3.  Make a quick plot with `.plot()` to make sure the download worked.\n",
        "> 4.  Run the cell to load the data into Python"
      ],
      "id": "ec0407c1-7768-430a-ae03-0e14ae4f559e"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Open up the ecoregions boundaries\n",
        "gdf = gpd.read_file(a_path)\n",
        "\n",
        "# Name the index so it will match the other data later on\n",
        "gdf.index.name = 'ecoregion'\n",
        "\n",
        "# Plot the ecoregions to check download"
      ],
      "id": "7e81c050"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create a simplified `GeoDataFrame` for plotting\n",
        "\n",
        "Plotting larger files can be time consuming. The code below will\n",
        "streamline plotting with `hvplot` by simplifying the geometry,\n",
        "projecting it to a Mercator projection that is compatible with\n",
        "`geoviews`, and cropping off areas in the Arctic.\n",
        "\n",
        "> **<i class=\"fa fa-solid fa-keyboard fa-large\" aria-label=\"keyboard\"></i>\n",
        "> Your task**\n",
        ">\n",
        "> Download and save ecoregion boundaries from the EPA:\n",
        ">\n",
        "> 1.  Make a copy of your ecoregions `GeoDataFrame` with the `.copy()`\n",
        ">     method, and save it to another variable name. Make sure to do\n",
        ">     everything else in this cell with your new copy!\n",
        "> 2.  Simplify the ecoregions with `.simplify(1000)`, and save it back\n",
        ">     to the `geometry` column.\n",
        "> 3.  Change the Coordinate Reference System (CRS) to Mercator with\n",
        ">     \\`.to_crs(ccrs.Mercator())\n",
        "> 4.  Use the plotting code in the cell to check that the plotting runs\n",
        ">     quickly and looks the way you want, making sure to change `gdf` to\n",
        ">     YOUR `GeoDataFrame` name."
      ],
      "id": "76fd2067-ed29-4e53-801a-dbbd2bd55908"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make a copy of the ecoregions\n",
        "\n",
        "# Simplify the geometry to speed up processing\n",
        "\n",
        "# Change the CRS to Mercator for mapping\n",
        "\n",
        "# Check that the plot runs\n",
        "gdf.hvplot(geo=True, crs=ccrs.Mercator())"
      ],
      "id": "dc38c93d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Download occurrence data\n",
        "\n",
        "You will use a database called the [Global Biodiversity Information\n",
        "Facility (GBIF)](https://www.gbif.org/). GBIF is compiled from species\n",
        "observation data all over the world, and includes everything from museum\n",
        "specimens to photos taken by citizen scientists in their backyards.\n",
        "\n",
        "> **<i class=\"fa fa-solid fa-keyboard fa-large\" aria-label=\"keyboard\"></i>\n",
        "> Your task**\n",
        ">\n",
        "> Download data from GBIF:\n",
        ">\n",
        "> 1.  Add parameters to the GBIF download function to limit your query"
      ],
      "id": "a6d128cf-8b77-4663-b293-030a9e6a8c46"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download meadowlark occurrence observations from GBIF\n",
        "gbif_api_endpoint = 'https://api.gbif.org/v1/occurrence/search'\n",
        "\n",
        "# Some of the columns are not present in all records\n",
        "# Extract the ones we need so the file loads without errors\n",
        "columns = [\n",
        "    'key', 'occurrenceID', 'basisOfRecord', 'occurrenceStatus',\n",
        "    'genus', 'species', \n",
        "    'decimalLatitude', 'decimalLongitude', 'continent', \n",
        "    'eventDate', 'month'\n",
        "]\n",
        "\n",
        "gbif_paths = []\n",
        "# We need to download for each month to avoid the record limit\n",
        "for month in range(1, 13):\n",
        "    # Format monthly path\n",
        "    gbif_path = gbif_path_tmpl.format(month=month)\n",
        "\n",
        "    # Resume previous download\n",
        "    offset = 0 \n",
        "    if os.path.exists(gbif_path):\n",
        "        offset = len(pd.read_csv(gbif_path))\n",
        "    \n",
        "    end_of_record = False\n",
        "    limit = 300\n",
        "    pbar = False\n",
        "    while not end_of_record:\n",
        "        # Query the GBIF API\n",
        "        gbif_parameters = dict(\n",
        "            continent='NORTH_AMERICA',\n",
        "            speciesKey='9596413',\n",
        "            hasCoordinate='true',\n",
        "            year=2023, month=month,\n",
        "            limit=limit, offset=offset\n",
        "        )\n",
        "        gbif_response = requests.get(gbif_api_endpoint, params=gbif_parameters)\n",
        "        # Make sure the download went through\n",
        "        gbif_response.raise_for_status()\n",
        "        gbif_json = gbif_response.json()\n",
        "        \n",
        "        if len(gbif_json['results'])>0:\n",
        "            # Add results to DataFrame\n",
        "            pd.DataFrame(gbif_json['results'])[columns].to_csv(\n",
        "                gbif_path, mode='a',\n",
        "                index=False, header=(offset==0))\n",
        "\n",
        "        # Prepare for next loop\n",
        "        end_of_record = gbif_json['endOfRecords']\n",
        "        offset += limit\n",
        "        if not pbar:\n",
        "            pbar = tqdm.tqdm(total=gbif_json['count'])\n",
        "            pbar.update(offset)\n",
        "        pbar.update(limit)"
      ],
      "id": "17dff431"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the GBIF data into Python"
      ],
      "id": "0043de4a-fdcd-4c6c-827d-6c7eeaf574a5"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "gbif_paths = []\n",
        "# Load and format the GBIF data\n",
        "gbif_dfs = []\n",
        "for month in range(1, 13):\n",
        "    # Format the monthly path\n",
        "    gbif_path = gbif_path_tmpl.format(month=month)\n",
        "\n",
        "    # Load the data\n",
        "    gbif_df = pd.read_csv(gbif_path, index_col='key')\n",
        "\n",
        "    # Select the required columns and append\n",
        "    gbif_dfs.append(gbif_df[['decimalLatitude', 'decimalLongitude', 'month']])\n",
        "\n",
        "# Glue the monthly DataFrames together\n",
        "gbif_df = pd.concat(gbif_dfs)"
      ],
      "id": "b8b986f6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert the GBIF data to a GeoDataFrame"
      ],
      "id": "389fc1a3-0b28-4d1d-98e3-5bd4f676a986"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "gbif_gdf = (\n",
        "    gpd.GeoDataFrame(\n",
        "        gbif_df, \n",
        "        geometry=gpd.points_from_xy(\n",
        "            gbif_df.decimalLongitude, \n",
        "            gbif_df.decimalLatitude), \n",
        "        crs=\"EPSG:4326\")\n",
        "    # Select the desired columns\n",
        "    [['month', 'geometry']]\n",
        ")\n",
        "gbif_gdf"
      ],
      "id": "99ff9147"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Identify the ecoregion for each observation"
      ],
      "id": "681d73d4-d9c7-44a7-835b-948b01977853"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "gbif_ecoregion_gdf = (\n",
        "    ecoregions_gdf\n",
        "    # Match the CRS\n",
        "    .to_crs(gbif_gdf.crs)\n",
        "    # Name the index to match the ecoregion index\n",
        "    .reset_index(names='ecoregion')\n",
        "    # Find ecoregion for each observation\n",
        "    .sjoin(\n",
        "        gbif_gdf.reset_index(names='observation'),\n",
        "        how='inner', \n",
        "        predicate='contains')\n",
        "    # Select the required columns\n",
        "    [['ecoregion', 'month', 'name']]\n",
        ")\n",
        "gbif_ecoregion_gdf"
      ],
      "id": "50823c5d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count the observations in each ecoregion"
      ],
      "id": "ef8adcfb-4996-42f6-a625-99d11e849ad7"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "occurrence_df = (\n",
        "    gbif_ecoregion_gdf\n",
        "    .groupby(['ecoregion', 'month'])\n",
        "    .agg(occurrences=('name', 'count'))\n",
        ")\n",
        "\n",
        "# Get rid of rare observation noise (possible misidentification?)\n",
        "occurrence_df = occurrence_df[occurrence_df.occurrences>1]\n",
        "\n",
        "# Take the mean by ecoregion\n",
        "mean_occurrences_by_ecoregion = (\n",
        "    occurrence_df\n",
        "    .reset_index()\n",
        "    .groupby(['ecoregion'])\n",
        "    .mean()\n",
        "    .occurrences\n",
        ")\n",
        "# Take the mean by month\n",
        "mean_occurrences_by_month = (\n",
        "    occurrence_df\n",
        "    .reset_index()\n",
        "    .groupby(['month'])\n",
        "    .mean()\n",
        "    .occurrences\n",
        ")\n",
        "\n",
        "# Normalize the observations by the monthly mean throughout the year\n",
        "occurrence_df['norm_occurrences'] = (\n",
        "    occurrence_df.occurrences \n",
        "    / mean_occurrences_by_ecoregion\n",
        "    / mean_occurrences_by_month\n",
        ")\n",
        "occurrence_df"
      ],
      "id": "439b88f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot the Tasiyagnunpa observations by month"
      ],
      "id": "9769c30a-3b46-482b-a537-ea6ba05c3169"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare a GeoDataFrame for plotting\n",
        "occurrence_gdf = (\n",
        "    ecoregions_plot_gdf\n",
        "    .join(occurrence_df)\n",
        "    .sort_values('month')\n",
        ")\n",
        "\n",
        "# Add a month name column\n",
        "# occurrence_gdf['Month'] = pd.to_datetime(\n",
        "#     occurrence_gdf.reset_index().month)#, format='%m')#.dt.month_name()\n",
        "\n",
        "occurrence_gdf"
      ],
      "id": "8b47c15c"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the plot bounds so they don't change with the slider\n",
        "xmin, ymin, xmax, ymax = occurrence_gdf.total_bounds\n",
        "\n",
        "# Plot occurrence by ecoregion and month\n",
        "migration_plot = occurrence_gdf.hvplot(\n",
        "    c='norm_occurrences',\n",
        "    geo=True, crs=ccrs.Mercator(), tiles='CartoDark',\n",
        "    title=\"Tasiyagnunpa migration\",\n",
        "    groupby='month',\n",
        "    xlim=(xmin, xmax), ylim=(ymin, ymax),\n",
        "    frame_width=600\n",
        ")\n",
        "\n",
        "# Put slider on the bottom\n",
        "hv.output(widget_location='bottom')\n",
        "\n",
        "hv.save(migration_plot, 'migration.html')\n",
        "migration_plot"
      ],
      "id": "3ddf1a78"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  }
}