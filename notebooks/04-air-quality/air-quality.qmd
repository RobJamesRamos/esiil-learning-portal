---
title: Mapping Wildfire Smoke
jupyter: python3
format:
  html: default
  ipynb:
    output-file: air-quality.ipynb
---

In 2023, wildfires burning across Canada caused smoke plumes and hazardous air quality across much of the US.

## Observing air quality from space

We will look at the air quality through a measurement called Aerosol Optical Thickness (AOT). How does it work? First, we need to learn about spectral reflectance signatures.

::: {.callout-important icon="false"}
## {{< fa fa-keyboard >}} Import necessary libraries
In the cell below, making sure to keep the packages in order, add packages for:

  * Working with DataFrames
  * Working with GeoDataFrames
  * Building reproducible file paths
  * Finding file paths using a pattern

{{< fa fa-circle-question >}} What are we using the rest of these packages for? See if you can figure it out as you complete the notebook.
:::

```{python}

```

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
import getpass
import json
import os
import pathlib
from glob import glob

import earthaccess
import geopandas as gpd
import hvplot.pandas
import hvplot.xarray
import pandas as pd
import rioxarray as rxr
import rioxarray.merge as rxrmerge
import xarray as xr

# Set up GDAL to retry data downloads if service is temporarily down
os.environ["GDAL_HTTP_MAX_RETRY"] = "5"
os.environ["GDAL_HTTP_RETRY_DELAY"] = "5"
```
:::

We have one more setup task. We're not going to be able to load all our data directly from the web to Python. That means we need to set up a place for it.

::: {.callout-caution icon="false"}
# {{< fa exclamation size=large >}} GOTCHA ALERT

A lot of times in Python we say "directory" to mean a "folder" on your computer. The two words mean the same thing in this context.
:::

::: {.callout-important icon="false"}
# {{< fa keyboard size=large >}} Your task

In the cell below, replace 'my-data-folder' with a **descriptive** directory name.
:::

```{python}

```

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
data_dir = os.path.join(
    pathlib.Path.home(), 'earth-analytics', 'data', 'denver-air-quality')
# Make the data directory
os.makedirs(data_dir, exist_ok=True)
```
:::

## Study Area: Cameron Peak Fire Boundary

### Earth Data Science data formats

In Earth Data Science, we get data in three main formats:

|  Data type  |  Descriptions | Common file formats | Python type |
|-------------|---------------|---------------------|-------------|
| Time Series | The same data points (e.g. streamflow) collected multiple times over time | Tabular formats (e.g. .csv, or .xlsx) | pandas DataFrame |
| Vector | Points, lines, and areas (with coordinates) | Shapefile (often an archive like a `.zip` file because a Shapefile is actually a collection of at least 3 files) | geopandas GeoDataFrame |
| Raster | Evenly spaced spatial grid (with coordinates) | GeoTIFF (`.tif`), NetCDF (`.nc`), HDF (`.hdf`)| rioxarray DataArray |

::: {.callout-warning icon="false"}
# {{< fa glasses size=large >}} Read more

Check out the sections about about [vector data](https://www.earthdatascience.org/courses/use-data-open-source-python/intro-vector-data-python/spatial-data-vector-shapefiles/) and [raster data](https://www.earthdatascience.org/courses/intro-to-earth-data-science/file-formats/use-spatial-data/use-raster-data/) in the textbook.
:::

::: {.callout-note icon="false"}
# {{< fa pencil size=large >}} What do you think?

For this coding challenge, we are interested in the boundary of Denver, CO. In the cell below, answer the following question: **What data type do you think the state boundary will be?**
:::


::: {.callout-important icon="false"}
# {{< fa keyboard size=large >}} Your task:

  1. **Find** the `COUNTY` folder in the [TIGER Census Line and Shapefiles File Transfer Protocol (FTP) archive](https://www2.census.gov/geo/tiger/TIGER2023/).
  2. Copy the URL for all the US States.
  3. **Load the data into Python** using the `geopandas` library, e.g.:
     ```python
     gpd.read_file(url)
     ```
  4. Select only Colorado
  5. **Call** your data at the end of the cell for testing.
:::

```{python}
# Download US State Boundaries

# Select only Colorado
```

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
denver_path = os.path.join(data_dir, 'denver-boundary')
if not os.path.exists(denver_path):
    # Download US County Boundaries
    county_url = (
        "https://www2.census.gov/geo/tiger/TIGER2023"
        "/COUNTY/tl_2023_us_county.zip")
    county_gdf = gpd.read_file(county_url)

    # Select only Colorado
    denver_gdf = county_gdf[county_gdf.NAME=="Denver"]
    denver_gdf.to_file(denver_path)

denver_gdf = gpd.read_file(denver_path)
denver_gdf
```
:::

```{python}
ans_gdf = _

assert isinstance(ans_gdf, gpd.GeoDataFrame), 'Your answer is not a GeoDataFrame'
assert len(ans_gdf)==1, 'Your answer should only have one row (Colorado)'

print(
    'Congratulations! You imported a GeoDataFrame '
    'and selected a single row')
```

### Site Map

We always want to create a site map when working with geospatial data. This helps us see that we're looking at the right location, and learn something about the context of the analysis.

::: {.callout-important icon="false"}
# {{< fa keyboard size=large >}} Your task

  * Plot your Denver boundary on an interactive map
  * Make sure to add a title
  * Add ESRI World Imagery as the basemap/background using the `tiles=...` parameter
:::

```{python}
# Plot the Denver boundary
```

::: {.content-visible when-format="html"}
```{python}
# Plot the Denver boundary
denver_gdf.hvplot(
    title='Colorado, USA',
    geo=True, tiles='EsriImagery',
    line_color='skyblue', line_width=3, fill_color=None)
```
:::

## Exploring the earthaccess API for NASA Earthdata access

Over the next four cells, you will download MODIS AOD data for the study period. MODIS is a multispectral instrument that measures. There are two MODIS sensors on two different platforms: satellites Terra and Aqua.

::: {.callout-warning icon="false"}
# {{< fa glasses size=large >}} Read more

[Learn more about MODIS datasets and the science they support](https://modis.gsfc.nasa.gov/)
:::

Since we're asking only for data thatcovers our study area, we can't just find a link to the data - we have to negotiate with the data server. We're doing this using the [earthaccess](https://www.earthdata.nasa.gov/learn/blog/earthaccess) API (Application Programming Interface), which implements the `fsspec` protocol for accessing spatiotemporal data. The API makes it possible for you to request data using code. You can use code from the `earthaccess` library to handle the API request.

::: {.callout-important icon="false"}
# {{< fa keyboard size=large >}} Your task

Often when we want to do something more complex in coding we find an example and modify it. This download code is already almost a working example. Your task will be:
  * 

{{< fa circle-question size=large >}} What would the product and layer name be if you were trying to download Ozone data from the Aqua MODIS platform instead of MODIS AOD?
:::

```{python}
# Search EarthData for MODIS Aerosol data
```

```{python}
# Search EarthData for MODIS Aerosol dataset
earthaccess.login(strategy="interactive", persist=True)
granules = earthaccess.search_data(
    short_name="MCD19A2", 
    cloud_hosted=True,
    bounding_box=tuple(denver_gdf.total_bounds),
    temporal=("2023-05-01", "2023-05-31"),
)
```

```{python}
modis_path = os.path.join(data_dir, 'modis-hr-aerosol')
earthaccess.download(granules, modis_path)
```


## Putting it together: Working with multi-file raster datasets in Python

Now you need to load all the downloaded files into Python. Let's start by getting all the file names. You will also need to extract the date from the filename. Check out [the lesson on getting information from filenames in the textbook](https://www.earthdatascience.org/courses/intro-to-earth-data-science/write-efficient-python-code/loops/data-workflows-with-loops/).

::: {.callout-caution icon="false"}
# {{< fa exclamation size=large >}} GOTCHA ALERT

`glob` doesn't necessarily find files in the order you would expect. Make sure to **sort** your file names like it says in the textbook.
:::

```{python}
# Get a list of MODIS HDF file paths
```

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
# Get list of MODIS HDF file paths
aod_paths = sorted(glob(os.path.join(modis_path, '*.hdf')))
len(aod_paths)
```
:::

### Repeating tasks in Python

Now you should have a few dozen files! For each file, you need to:

  * Load the file in using the `rioxarray` library
  * Get the date from the file name
  * Add the date as a dimension coordinate
  * Give your data variable a name
  * Divide by the scale factor of 10000

You don't want to write out the code for each file! That's a recipe for copy pasta. Luckily, Python has tools for doing similar tasks repeatedly. In this case, you'll use one called a `for` loop.

There's some code below that uses a `for` loop in what is called an **accumulation pattern** to process each file. That means that you will save the results of your processing to a list each time you process the files, and then merge all the arrays in the list. 

::: {.callout-important icon="false"}
# {{< fa keyboard size=large >}} Your task

  * Look at the file names. How many characters from the end is the date?
  * Replace any required variable names with your chosen variable names
  * Change the `scale_factor` variable to be the correct scale factor for this aod dataset
  * Using indices or regular

:::

```{python}
doy_start = -1
doy_end = -1
```

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
doy_start = -36
doy_end = -29
```
:::

```{python}
# Import air quality data to Python

crs = (
    "+proj=sinu +a=6371007.181 +b=6371007.181 +lon_0=0 "
    "+x_0=0 +y_0=0 +units=m +no_defs"
)

aod_das_by_date = {}
for aod_path in aod_paths:
    # Get date from file name
    doy = aod_path[doy_start:doy_end]
    date = pd.to_datetime(doy, format='%Y%j')

    # Open dataset
    variable = 'Optical_Depth_047'
    da = rxr.open_rasterio(
        aod_path, variable=variable, masked=True
    ).squeeze()[variable]

    # Write CRS to make sure it is correct
    da = da.rio.write_crs(crs)

    # Reproject the data
    da = da.rio.reproject(denver_gdf.crs)

    # Assign date coordinates
    da = da.assign_coords({'date': date})
    da = da.expand_dims({'date': 1})
    da = da.sel(band=1)
    da = da.transpose('date', 'y', 'x')
    
    if not (doy in aod_das_by_date):
        aod_das_by_date[doy] = []
    aod_das_by_date[doy].append(da)
```

```{python}
aod_das = []
for doy, das in aod_das_by_date.items():
    da = rxrmerge.merge_arrays(das)

    # Crop the data
    da = da.rio.clip(denver_gdf.envelope)

    # Prepare for concatenation
    aod_das.append(da)
    
len(aod_das)
```

Next, stack your arrays by date into a time series using the `xr.combine_by_coords()` function. You will have to tell it which dimension you want to stack your data in.

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
aod_da = xr.combine_by_coords(
  aod_das, 
  coords=['date'], 
  combine_attrs='drop_conflicts')
aod_da
```
:::


:::{.callout-important icon="false"}
# {{< fa keyboard size=large >}} Plot AOD anomaly spatially

Complete the following:
  * Select data from 2021 to 2023 (3 years after the fire)
  * Take the temporal mean (over the **date**, not spatially)
  * Get the AOD variable (should be a DataArray, not a Dataset)
  * Repeat for the data from 2018 to 2020 (3 years before the fire)
  * Subtract the 2018-2020 time period **from** the 2021-2023 time period
  * Plot the result using a **diverging** color map like `cmap=plt.cm.PiYG`

> There are different types of color maps for different types of data. In this case, we want decreases to be a different color from increases, so we should use a **diverging** color map. Check out available colormaps in the [matplotlib documentation](https://matplotlib.org/stable/tutorials/colors/colormaps.html).

{{< fa pepper-hot size=large >}} For an extra challenge, add the fire boundary to the plot
:::

```{python}
#| error: true
# Compute the difference between AOD on May 22nd and the average AOD

# Plot the difference
(
    aod_diff.hvplot(x='', y='', cmap='', geo=True)
    *
    gdf.hvplot(geo=True, fill_color=None, line_color='black')
)
```

:::{.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!
aod_diff = (
    aod_da.sel(date=slice('2023-05-19', '2023-05-26')).mean('date')[variable]
    # Subtract the typical (mean) value for the month
    - aod_da.mean('date')[variable]
)

(
    aod_diff.hvplot(
        x='x', y='y', geo=True, 
        cmap='PiYG_r', alpha=0.75,
        xlabel='Longitude', ylabel='Latitude', clabel='Difference in AOD')
    * denver_gdf.hvplot(geo=True, tiles='CartoLight', fill_color='none', line_color='black')
).opts(
    title='Figure 3: Denver, CO Air Quality Anomaly May 19-25',
)
```
:::

# Does the AOD spike during this time period?

You will compute the mean AOD inside and outside the fire boundary. First, use the code below to get a `GeoDataFrame` of the area outside the Reservation. Your task:
  * Check the variable names - Make sure that the code uses your boundary `GeoDataFrame`
  * How could you test if the geometry was modified correctly? Add some code to take a look at the results.


::: {.callout-important icon="false"}
# {{< fa keyboard size=large >}} Your Task
For **both inside and outside** the fire boundary:

  * Group the data by year
  * Take the mean. You always need to tell reducing methods in `xarray` what dimensions you want to reduce. When you want to summarize data across **all** dimensions, you can use the `...` syntax, e.g. `.mean(...)` as a shorthand.
  * Select the AOD variable
  * Convert to a DataFrame using the `to_dataframe()` method
  * Join the two DataFrames for plotting using the `.join()` method. You will need to rename the columns using the `lsuffix=` and `rsuffix=` parameters
:::

::: {.callout-caution icon="false"}
# {{< fa exclamation size=large >}} GOTCHA ALERT

The DateIndex in pandas is a little different from the Datetime Dimension in xarray. You will need to use the `.dt.year` syntax to access information about the year, not just `.year`.
:::

Finally, plot annual July means for both inside and outside the Reservation on the same plot.

:::

```{python}
# Compute mean annual July AOD
```

::: {.content-visible when-format="html"}
```{python}
#| code-fold: true
#| code-summary: See our solution!

aod_da.groupby('date').max(...).dropna('date').hvplot(
    title='Air Pollution in Denver during May 2023',
    xlabel='Date'
)
```
:::

## Your turn! Repeat this workflow in a different time and place.

It's not just fires that affect AOD! You could look at: 

  * Traffic or industrial pollution
  * Dust storms
