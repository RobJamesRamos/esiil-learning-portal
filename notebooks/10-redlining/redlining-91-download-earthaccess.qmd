# Download Data with `earthaccess`

## STEP 1: Set up

Load your stored variables into memory:

```{python}
#| eval: true
%store -r denver_redlining_gdf data_dir
```

::: {.callout-task title='Import packages'}

Add imports for packages that help you:

  1. Work with the file system interoperably
  2. Work with vector data
  3. Create interactive plots of vector data
  4. Group and aggregate tabular data
:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True
import re # Use regular expressions to extract metadata

import earthaccess # Access NASA data from the cloud
# Overlay raster and vector data
import numpy as np # Process bit-wise cloud mask
# Group and aggregate
# Work with raster data
from rioxarray.merge import merge_arrays # Merge rasters
```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
import os # Interoperable file paths
import pathlib # Find the home folder
import re # Use regular expressions to extract metadata

import earthaccess # Access NASA data from the cloud
import matplotlib.pyplot as plt # Overlay raster and vector data
import numpy as np # Process bit-wise cloud mask
import pandas as pd # Group and aggregate
import rioxarray as rxr # Work with raster data
from rioxarray.merge import merge_arrays # Mosaic rasters
```
:::

::: {.callout-task title='Set up `earthaccess` connection'}

1. Make an account on the [earthdata site](https://urs.earthdata.nasa.gov/). You don't need to spend a lot of time on the registration form -- go ahead answer their questions to the best of your ability. That information is used for internal reporting and analysis, not to decide whether or not to grant you an account!
2. Run the code below an enter your credentials to log into earthaccess from Python. You should only need to do this once, as long as `persist=True` is set.

:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True
earthaccess.login(strategy="interactive", persist=True)
```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
earthaccess.login(strategy="interactive", persist=True)
```
:::


## STEP 2: Search
::: {.callout-task title='Search for HLS data'}

It can be useful to use NASA's online resources to find the data you want to download before accessing it over API. To do that:

  1. Go to the [NASA Worldview Site](https://worldview.earthdata.nasa.gov/) and search for Denver, CO.
  2. Add the `HLSL30` product as a base map. You can do this by clicking `Add Layer` and then searching for the **short name** `HLSL30`. When looking for other datasets, the short name can usually be found by on the data homepage, accessible from the **doi**. Practice opening the data page for `HLSL30` to find where the shortcode is.
  3. By dragging the date indicator on the bottom, search the month of July, 2023 for a day that has data available and little to no cloud cover over Denver. You may need to wait a second or so for the data to load for any given date.

Now, using the code below:

  1. Put the short name of the dataset into the `earthaccess.search_data()` function.
  2. Replace `gdf` with the name of your denver redlining `GeoDataFrame`.
  3. Put the date you found into the `temporal` parameter, replacing `YYYY-MM-DD` with the appropriate year (Y), month (M), and day (D) digits.
  4. Run the code and make sure there are results! If not, double check your date.

:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True
denver_results = earthaccess.search_data(
    short_name="",
    bounding_box=tuple(gdf.total_bounds),
    temporal=("YYYY-MM-DD"),
    count=1
)
denver_results
```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
denver_results = earthaccess.search_data(
    short_name='HLSL30',
    bounding_box=tuple(denver_redlining_gdf.total_bounds),
    temporal=("2023-07-12", "2023-07-12"),
    count=1
)
denver_results
```
:::

## STEP 3: Open data connections

::: {.callout-task title='Access HLS data'}

:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True

```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
ea_uris = earthaccess.open(denver_results)
ea_uris
```
:::

## STEP 4: Process data

### Connect with Python

Right now, you have **file connections** with your data in the cloud, but you haven't actually downloaded anything. `earthaccess` uses a **lazy** virtual file connection (vsi), meaning that it doesn't download anything until you ask for specific numbers, like when you plot. In addition, many operations can be performed on the server side, such as selecting data by index and summary operations.

::: {.callout-task title='Practice importing multispectral data'}
To load in the green band of data to work with them:

  1. **Find a green layer:** Check out the [HLSL30 User Guide](https://hls.gsfc.nasa.gov/wp-content/uploads/2019/01/HLS.v1.4.UserGuide_draft_ver3.1.pdf). Which layer is the green layer? What is its **index** in the list of files you got from `earthaccess`? Remember that Python starts counting at 0!
  2. **Open the layer:** Open one of **green** layers you downloaded using the `rxr.open_rasterio()` function. You can do this by index if you like -- this code is for you to explore using the data. Don't forget to `.squeeze()`! But, hold off on masking and scaling so you can see what it looks like to have unmasked nodata values in your `DataArray`.
  3. **Mask nodata values and apply the scale factor:** Now, plot your Data Array. Notice that many of the values are somewhere around -10000. We can guess, because it's common in datasets like this, that the value -9999 is used here as a "no data" value to mark where no measurement was taken. To encode the no data values correctly, add the parameter `mask_and_scale=True` to the `rxr.open_rasterio()` function. Now, the image should be white where there's no data, the values should range between 0 and 1.
  4. Try out your file connection to see how long different operations take. You can try taking the `.mean()` of your data (fast -- this happens on the server), and plotting your data (slow -- you have to download the whole tile to plot this way). Next, add the study boundary onto the image. Notice that you have quite a bit more data than you need!
:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True
# Import one tile of green data

```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
green_da = rxr.open_rasterio(
    ea_uris[8], mask_and_scale=True).squeeze()
green_da.plot(cmap='Greens', vmin=0, robust=True)
denver_redlining_gdf.to_crs(green_da.rio.crs).plot(ax=plt.gca())
```
:::


### Crop

Plotting a whole HLSL30 tile probably took about 30 seconds to download and plot the data, but we know that some operations can be performed without downloading. One of this is **cropping** the raster image by index using the `.rio.clip_box()` method. Note that `.rio.clip()` clips the data to a boundary instead of a rectangle, and will trigger a full download.

We almost always want to crop before doing *anything* else. Cropping usuallyreduces the amount of data you need dramatically, which makes everything faster.

In this example, our study area vector data and our raster multispectral reflectance data come in different **Coordinate Reference System**s (CRSs). Before using them together, you will need to convert the vector data to be in the same CRS as the raster data.

::: {.callout-important title='Why convert vector data?'}
You're being asked to convert vector data to the raster CRS instead of the other way around for two specific reasons. One is that vector data is usually smaller than raster data and converts faster. The other is that converting the CRS of a raster file means that the centers of the grid cells will be in slightly different locations because grids do not transfer over. This requires some kind of **interpolation**, which can be computationally costly and also have the potential to introduce error.
:::

::: {.callout-task title='Get your study bounds'}

  1. Access the CRS of the redlining data (`.crs`) and the reflectance data (`.rio.crs`) to verify that they are not the same
  2. Convert the redlining `GeoDataFrame` to the same CRS as the reflectance data.
  3. Get the `.total_bounds` of the redlining data so you can crop to it.
:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True
# Get the study bounds
```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
denver_bounds = (
    denver_redlining_gdf
    .to_crs(green_da.rio.crs)
    .total_bounds
)
denver_bounds
```
:::

Now, you're ready to crop.

::: {.callout-task title='Crop raster data'}

To crop your data, use the method `.rio.clip_box(*your_bounds_here)`.

The asterisk **unpacks** the bounds so that they go in as four separate arguments instead of a single tuple.

You can also practice cloud masking again here if you like. Note that you will also need to crop your cloud mask!
:::

```{python}
#| echo: True
#| eval: False
#| class: student-code
#| highlight: True
# Crop the green reflectance data
```

::: {.content-visible when-format="html"}
```{python}
#| echo: True
#| eval: True
#| code-fold: True
#| code-summary: See our solution!
#| class: answer-code
#| highlight: True
green_cropped_da = green_da.rio.clip_box(*denver_bounds)
green_cropped_da.plot(cmap='Greens', vmin=0, robust=True)
```
:::

Congratulations -- you've accessed some data from the cloud!

::: {.content-hidden}
```{python}
#| eval: false
import os
import shutil
import subprocess

import earthaccess
import rioxarray as rxr

zip_name = "redlining-foundations-data"
to_zip_dir = os.path.join(data_dir, 'tmp', zip_name)
os.makedirs(to_zip_dir, exist_ok=True)

earthaccess.login(strategy="interactive", persist=True)
results = earthaccess.search_data(
    short_name='HLSL30',
    bounding_box=tuple(denver_redlining_gdf.total_bounds),
    temporal=("2023-07-12", "2023-07-12"),
    count=1
)
ea_uris = earthaccess.open(results)

for uri in ea_uris:
    da_path = os.path.join(to_zip_dir, uri.full_name.split('/')[-1])
    da = rxr.open_rasterio(uri)
    bounds_proj = denver_redlining_gdf.to_crs(da.rio.crs).total_bounds
    cropped_da = da.rio.clip_box(*bounds_proj)
    cropped_da.rio.to_raster(da_path)

shutil.make_archive(to_zip_dir, 'zip', to_zip_dir)
try:
    subprocess.run([
        'gh', 'release', 'upload', 'data-release',
        to_zip_dir + '.zip',
        '--repo', 'cu-esiil-edu/esiil-learning-portal',
        '--clobber'
        ])
except NameError:
    print('Looks like the current version of data has already been uploaded.')

shutil.rmtree(os.path.join(data_dir, 'tmp'))
```
:::