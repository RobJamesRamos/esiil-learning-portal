# Bulk Download Data with `earthaccess`

Whew -- we've processed some reflectance data! But you may have noticed that your image doesn't include all of Denver, or all the spectral bands you will need -- Your search returned 60 different files covering different spectral bands and spatial areas! To work with all of them, we will have to utilize **DRY** coding techniques -- `for` loops and functions.

First things first -- load your stored variables into memory:

```{python}
#| eval: true
%store -r denver_redlining_gdf data_dir
```

::: {.callout-task title='Import packages'}

Add imports for packages that help you:

  1. Work with the file system interoperably
  2. Work with vector data
  3. Create interactive plots of vector data
  4. Group and aggregate tabular data
:::

```{python}
#| template: student
# Interoperable file paths
import re # Use regular expressions to extract metadata

import earthaccess # Access NASA data from the cloud
# Overlay plots
import numpy as np # Process bit-wise cloud mask
# Group and aggregate
# Work with raster data
from rioxarray.merge import merge_arrays # Merge rasters
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
import os # Interoperable file paths
import re # Use regular expressions to extract metadata

import earthaccess # Access NASA data from the cloud
import matplotlib.pyplot as plt # Overlay plots
import numpy as np # Process bit-wise cloud mask
import pandas as pd # Group and aggregate
import rioxarray as rxr # Work with raster data
from rioxarray.merge import merge_arrays # Mosaic rasters
```
:::

::: {.callout-task title='Set up `earthaccess` connection'}
As you did before, log in to your `earthaccess` account, search for the Denver data, and open the file connections. You will find that you have to re-run your search every time you access a file -- keep this in mind if you get errors later!
:::

```{python}
#| template: student
# Search earthaccess
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
earthaccess.login(strategy="interactive", persist=True)
denver_results = earthaccess.search_data(
    short_name='HLSL30',
    bounding_box=tuple(denver_redlining_gdf.total_bounds),
    temporal=("2023-07-12", "2023-07-12"),
    count=1
)
ea_uris = earthaccess.open(denver_results)
```
:::

## Putting it all together

To get a complete image, we will have to:

  1. Load in all 4 rasters that cover Denver
  2. Process them
  3. Merge, or mosaic, them into one image

And...we haven't even talked about the other bands you might need, or what to do if you want a time-series of images. You can see that if we were to copy and paste all the code above for each raster we need to load, it could get pretty overwhelming, and *very* error-prone. This is the opposite of what we mean by **DRY** (Don't Repeat Yourself) code.

Before we continue, we're going to make some functions to do the tasks you completed up above. We've already set up the code for you, identified **parameters** and **returns**, and added **docstrings** to document your function. When writing a function, we recommend the following process:

  1. Copy the code you're using into the function shell, making sure to indent it so Python knows it is part of the function.
  2. Identify any variables that are **too specific**. For example, if I called a `DataArray` `denver_da`, but I could use my function to process data from anywhere...I might change the name to `da` whereever it appears.
  3. Identify the function **parameters** or arguments and make sure they match your code. Python may let you, but we recommend not using variables defined outside the function inside the function -- if you need something in your function make sure to pass it in as a parameter!
  4. Identify the function **returns** and make sure they match your code. What do you want to be able to access at the end? Keep in mind that unless you return them, the variables you create in a function will be stuck there. The `return` statement at the end of your function will pass the variables you want to keep back out of the function.
  5. Write some code to test your function, such as by plotting the results. We recommend going line by line when you're just getting started. This usually involves commenting code later on, and modifying the returns and test code as you go.
  6. Restart the kernel and run your function to check that doesn't have any hidden requirements.

::: {.callout-task title="DRY code with functions"}
Take each processing step from above, and  create a function to do it. We recommend writing the following 2 functions:

  1. A function to load a raster, crop it, and apply the scale factor
  2. A function to process the cloud mask

Applying the cloud mask is a single line of code, so we don't think it needs its own function.

Make sure to test all your functions using your example from up top! 
:::

```{python}
#| template: student 
def process_image(uri, bounds_gdf):
    """
    Load, crop, and scale a raster image from earthaccess

    Parameters
    ----------
    uri: file-like or path-like
      File accessor downloaded or obtained from earthaccess
    bounds_gdf: gpd.GeoDataFrame
      Area of interest to crop to

    Returns
    -------
    cropped_da: rxr.DataArray
      Processed raster
    """

    return cropped_da
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
def process_image(uri, bounds_gdf):
    """
    Load, crop, and scale a raster image from earthaccess

    Parameters
    ----------
    uri: file-like or path-like
      File accessor downloaded or obtained from earthaccess
    bounds_gdf: gpd.GeoDataFrame
      Area of interest to crop to

    Returns
    -------
    cropped_da: rxr.DataArray
      Processed raster
    """
    # Open raster connection
    da = rxr.open_rasterio(uri, mask_and_scale=True).squeeze()

    # Crop raster
    bounds = bounds_gdf.to_crs(da.rio.crs).total_bounds
    cropped_da = da.rio.clip_box(*bounds)
    return cropped_da
```
:::

```{python}
#| template: student
def process_cloud_mask(cloud_uri, bounds_gdf, bits_to_mask):
    """
    Load an 8-bit Fmask file and process to a boolean mask

    Parameters
    ----------
    uri: file-like or path-like
      Fmask file accessor downloaded or obtained from earthaccess
    bounds_gdf: gpd.GeoDataFrame
      Area of interest to crop to
    bits_to_mask: list of int
      The indices of the bits to mask if set

    Returns
    -------
    cloud_mask: np.array
      Cloud mask
    """
    
    return cloud_mask
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
def process_cloud_mask(cloud_uri, bounds_gdf, bits_to_mask):
    """
    Load an 8-bit Fmask file and process to a boolean mask

    Parameters
    ----------
    uri: file-like or path-like
      Fmask file accessor downloaded or obtained from earthaccess
    bounds_gdf: gpd.GeoDataFrame
      Area of interest to crop to
    bits_to_mask: list of int
      The indices of the bits to mask if set

    Returns
    -------
    cloud_mask: np.array
      Cloud mask
    """
    cloud_da = process_image(cloud_uri, bounds_gdf)
    cloud_bits = (
        np.unpackbits(
            (
                # Get the cloud mask as an array...
                cloud_da.values
                # ... of 8-bit integers
                .astype('uint8')
                # With an extra axis to unpack the bits into
                [:, :, np.newaxis]
            ), 
            # List the least significant bit first to match the user guide
            bitorder='little',
            # Expand the array in a new dimension
            axis=-1)
    )
    cloud_mask = np.sum(
        # Select bits to mask
        cloud_bits[:,:,bits_to_mask], 
        # Sum along the bit axis
        axis=-1
    )
    # Check if any of the masked bits are true
    cloud_mask = cloud_mask == 0
    return cloud_mask

# green_da = process_image(ea_uris[8], denver_redlining_gdf)
# bits_to_mask = [
#     1, # Cloud
#     2, # Adjacent to cloud
#     3, # Cloud shadow
#     5, # Water
# ]
# cloud_mask = process_cloud_mask(
#     ea_uris[14], denver_redlining_gdf, bits_to_mask)
# green_masked_da = green_da.where(cloud_mask)
# green_masked_da.plot(cmap='Greens', vmin=0, robust=True)
```
:::

Our next new tool to help you write DRY and correct code is the regular expression. Regular expressions are a little like the patterns we use with `glob` that contain wildcard characters (`*`) -- but, they are **much** more powerful. With regular expressions, we can extract different segments from a string (file name, in this case) based on landmarks -- even if those segments are not always the same length!

First -- run another `earthaccess` search, this time removing the `count=1` argument, or setting it to `count=-1`. This will include all the results.

```{python}
#| template: student
# Search earthaccess

# Open earthaccess results
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
earthaccess.login(strategy="interactive", persist=True)
denver_results = earthaccess.search_data(
    short_name='HLSL30',
    bounding_box=tuple(denver_redlining_gdf.total_bounds),
    temporal=("2023-07-12", "2023-07-12"),
)
ea_uris = earthaccess.open(denver_results)
```
:::

::: {.callout-task title='Get metadata with **regular expressions**'}

Using the code below as a starting point, extract metadata from file names and put them into a `DataFrame`. This strategy will help you later on because you will be able to group rasters by their metadata values, such as tile ID, band ID, and/or date.

  1. Build your regular expression. ChatGPT is a great tool to get started with your regular expression. You can also check out [https://regex101.com/](https://regex101.com/) to test your regular expressions, making sure to select the `Python` regular expression engine.
  2. Replace file_name with a **string** version of the URI. You can access it from the object you got from `earthaccess` through the `.full_name` attribute.
  3. Add the URIs from `earthaccess` to the `DataFrame` you created as a new column. 
:::

```{python}
#| template: student
# Compile a regular expression to search for metadata
uri_re = re.compile(
    ...
)

# Find all the metadata in the file name
uri_groups = [
    uri_re.search(file_name_to_search).groupdict()
    for uri in ea_uris]

# Create a DataFrame with the metadata
raster_df = pd.DataFrame(uri_groups)

# Add the File-like URI to the DataFrame

# Check the results
raster_df

```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Compile a regular expression to search for metadata
uri_re = re.compile(
    r'HLS.L30.(?P<tile_id>[^.]*)'
    r'.(?P<date>\d*)'
    r'T\d*.v2.0.'
    r'(?P<band_id>[^.]*)'
    r'.tif'
)

# Find all the metadata in the file name
uri_groups = [
    uri_re.search(uri.full_name).groupdict()
    for uri in ea_uris]

# Create a DataFrame with the metadata
raster_df = pd.DataFrame(uri_groups)

# Add the File-like URI to the DataFrame
raster_df['uri'] = ea_uris

# Check the results
raster_df
```
:::


Now you are ready to run your code repeatedly on each raster you want to load. To do this, we'll use a structure called a `for` loop, which runs the same code repeatedly with different variable values. The values that change are special variables called **looping variables**.

To set up a `for` loop, you can use the following process:

  1. Copy the code you're using into the `for` loop shell, making sure to indent it so Python knows it is part of the loop.
  2. Identify any variables that are **too specific**. For example, if I called a `DataArray` `green_da`, but the loop will be processing data from other bands...I might change the name to `da` whereever it appears.
  3. Identify the **looping variable(s)** and make sure they match your code.
  4. Establish an **accumulator** -- a data structure to store the result. Add what you want to keep from each iteration of the loop to it.
  5. Write some code to test your loop, such as by printing out an intermediate value in the loop, or eventually plotting the final results. We recommend going line by line when you're just getting started. This usually involves commenting code later on, and modifying the accumulator and testing as you go. You can also use the `break` keywork to stop the loop after a single iteration for testing.

::: {.callout-task title='Process data'}
Process all your bands. We've provided the structure of the `for` loop -- you will need to call your functions and work out how to pass them the arguments they need.

Something that is tricky about looping through `DataFrame`s is that they tend to wrap values in external structures like `Series` (which are the data type of columns in a `DataFrame`). The print out of a `Series` containing one value and the print out of that value are not identical, but the are **very similar**. To get a **value** out from inside a `Series`, you can add the following code: `.values[0]`. This will first remove the `Series` wrapper, leaving an array, and the get the first value in the array.
:::


```{python}
#| template: student
# Labels for each band to process
bands = {
    'B02': 'red',
    ...
}
# Initialize structure for saving images
denver_das = {band_name: [] for band_name in bands.values()}
for tile_id, tile_df in raster_df.groupby('tile_id'):
    # Load the cloud mask

    for band_id, row in tile_df.groupby('band_id'):
        if band_id in bands:
            band_name = bands[band_id]
            # Process band

            # Mask band
            
            # Store the resulting DataArray ofr later
            denver_das[band_name].append(band_masked_da)

# Merge all tiles
denver_das = {
    band_name: merge_arrays(das) 
    for band_name, das 
    in denver_das.items()}

denver_das['green'].plot(cmap='Greens', robust=True)
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
# Labels for each band to process
bands = {
    'B02': 'blue',
    'B03': 'green',
    'B04': 'red',
    'B05': 'nir'
}
# Initialize structure for saving images
denver_das = {band_name: [] for band_name in bands.values()}
for tile_id, tile_df in raster_df.groupby('tile_id'):

    # Load the cloud mask
    cloud_mask = process_cloud_mask(
        tile_df.loc[tile_df.band_id=='Fmask', 'uri'].values[0],
        denver_redlining_gdf, 
        [1, 2, 3, 5])

    for band_id, row in tile_df.groupby('band_id'):
        if band_id in bands:
            band_name = bands[band_id]
            band_da = process_image(
                row.uri.values[0], 
                denver_redlining_gdf)
            band_masked_da = band_da.where(cloud_mask)
            denver_das[band_name].append(band_masked_da)

# Merge all tiles
denver_das = {
    band_name: merge_arrays(das) 
    for band_name, das 
    in denver_das.items()}

denver_das['green'].plot(cmap='Greens', robust=True)
```
:::

::: {.callout-task title='Check your data'}
Make a plot of one of your merged bands with the denver boundary superimposed. You should now have data for the whole city!
:::

```{python}
#| template: student
# Plot a merged raster band
```

::: {.content-visible when-format="html"}
```{python}
#| template: answer
denver_das['green'].plot(cmap='Greens', vmin=0, robust=True)
denver_redlining_gdf.to_crs(denver_das['green'].rio.crs).plot(
    ax=plt.gca(),
    edgecolor='black', color='none')
```
:::